{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"a0f30a25\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005951d030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0e7867626f6f73745f74756e696e67948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f61306633306132355f315f636f6e6669675f5f636f6c73616d706c655f6279747265653d302e373637342c636f6e6669675f5f6c6561726e696e675f726174653d302e303836362c636f6e6669675f5f6d61785f64657074683d332c636f6e6669675f5f6e5f657374696d61746f72733d3230302c636f6e5f323032352d30372d32355f31372d31342d3133948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c3e2f55736572732f657269636c69752f70726f6a65637473352f636f6e746578742d656e67696e656572696e672d696e74726f2f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d30372d32355f31372d31342d31339475622e\"\n  },\n  \"config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.08663630009554724,\n    \"config__n_estimators\": 200,\n    \"config__subsample\": 0.7868583819543982,\n    \"config__colsample_bytree\": 0.767395911847853,\n    \"config__reg_alpha\": 0.01072360267150972,\n    \"config__reg_lambda\": 4.4152357838959775\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.08663630009554724,\n    \"config__n_estimators\": 200,\n    \"config__subsample\": 0.7868583819543982,\n    \"config__colsample_bytree\": 0.767395911847853,\n    \"config__reg_alpha\": 0.01072360267150972,\n    \"config__reg_lambda\": 4.4152357838959775\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.08663630009554724,\n    \"config__n_estimators\": 200,\n    \"config__subsample\": 0.7868583819543982,\n    \"config__colsample_bytree\": 0.767395911847853,\n    \"config__reg_alpha\": 0.01072360267150972,\n    \"config__reg_lambda\": 4.4152357838959775\n  },\n  \"experiment_tag\": \"1_config__colsample_bytree=0.7674,config__learning_rate=0.0866,config__max_depth=3,config__n_estimators=200,config__reg_alpha=0.0107,config__reg_lambda=4.4152,config__subsample=0.7869\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_a0f30a25_1_config__colsample_bytree=0.7674,config__learning_rate=0.0866,config__max_depth=3,config__n_estimators=200,con_2025-07-25_17-14-13\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478055.4953809,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.6933333333333334,\n    \"cod_accuracy\": 0.3125,\n    \"timestamp\": 1753478055,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"a0f30a25\",\n    \"date\": \"2025-07-25_17-14-15\",\n    \"time_this_iter_s\": 0.2574300765991211,\n    \"time_total_s\": 0.2574300765991211,\n    \"pid\": 46558,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 3,\n      \"config__learning_rate\": 0.08663630009554724,\n      \"config__n_estimators\": 200,\n      \"config__subsample\": 0.7868583819543982,\n      \"config__colsample_bytree\": 0.767395911847853,\n      \"config__reg_alpha\": 0.01072360267150972,\n      \"config__reg_lambda\": 4.4152357838959775\n    },\n    \"time_since_restore\": 0.2574300765991211,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"1_config__colsample_bytree=0.7674,config__learning_rate=0.0866,config__max_depth=3,config__n_estimators=200,config__reg_alpha=0.0107,config__reg_lambda=4.4152,config__subsample=0.7869\"\n  },\n  \"last_result_time\": 1753478055.764228,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.6933333333333334,\n      \"min\": 0.6933333333333334,\n      \"avg\": 0.6933333333333334,\n      \"last\": 0.6933333333333334,\n      \"last-5-avg\": 0.6933333333333334,\n      \"last-10-avg\": 0.6933333333333334\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3125,\n      \"min\": 0.3125,\n      \"avg\": 0.3125,\n      \"last\": 0.3125,\n      \"last-5-avg\": 0.3125,\n      \"last-10-avg\": 0.3125\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.2574300765991211,\n      \"min\": 0.2574300765991211,\n      \"avg\": 0.2574300765991211,\n      \"last\": 0.2574300765991211,\n      \"last-5-avg\": 0.2574300765991211,\n      \"last-10-avg\": 0.2574300765991211\n    },\n    \"time_total_s\": {\n      \"max\": 0.2574300765991211,\n      \"min\": 0.2574300765991211,\n      \"avg\": 0.2574300765991211,\n      \"last\": 0.2574300765991211,\n      \"last-5-avg\": 0.2574300765991211,\n      \"last-10-avg\": 0.2574300765991211\n    },\n    \"time_since_restore\": {\n      \"max\": 0.2574300765991211,\n      \"min\": 0.2574300765991211,\n      \"avg\": 0.2574300765991211,\n      \"last\": 0.2574300765991211,\n      \"last-5-avg\": 0.2574300765991211,\n      \"last-10-avg\": 0.2574300765991211\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083096fc62c92fe63f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083096fc62c92fe63f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000d43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000d43f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd079bc00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd079bc00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd079bc00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd079bc00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd079bc00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd079bc00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5bc9351f\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.028591586779182922,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.704767493314535,\n    \"config__colsample_bytree\": 0.8909453074396879,\n    \"config__reg_alpha\": 0.00011397376840299625,\n    \"config__reg_lambda\": 1.915325362656138\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.028591586779182922,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.704767493314535,\n    \"config__colsample_bytree\": 0.8909453074396879,\n    \"config__reg_alpha\": 0.00011397376840299625,\n    \"config__reg_lambda\": 1.915325362656138\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.028591586779182922,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.704767493314535,\n    \"config__colsample_bytree\": 0.8909453074396879,\n    \"config__reg_alpha\": 0.00011397376840299625,\n    \"config__reg_lambda\": 1.915325362656138\n  },\n  \"experiment_tag\": \"3_config__colsample_bytree=0.8909,config__learning_rate=0.0286,config__max_depth=7,config__n_estimators=500,config__reg_alpha=0.0001,config__reg_lambda=1.9153,config__subsample=0.7048\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5bc9351f_3_config__colsample_bytree=0.8909,config__learning_rate=0.0286,config__max_depth=7,config__n_estimators=500,con_2025-07-25_17-14-17\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478059.55354,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.7066666666666668,\n    \"cod_accuracy\": 0.3375,\n    \"timestamp\": 1753478060,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5bc9351f\",\n    \"date\": \"2025-07-25_17-14-20\",\n    \"time_this_iter_s\": 0.6266558170318604,\n    \"time_total_s\": 0.6266558170318604,\n    \"pid\": 46585,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 7,\n      \"config__learning_rate\": 0.028591586779182922,\n      \"config__n_estimators\": 500,\n      \"config__subsample\": 0.704767493314535,\n      \"config__colsample_bytree\": 0.8909453074396879,\n      \"config__reg_alpha\": 0.00011397376840299625,\n      \"config__reg_lambda\": 1.915325362656138\n    },\n    \"time_since_restore\": 0.6266558170318604,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3_config__colsample_bytree=0.8909,config__learning_rate=0.0286,config__max_depth=7,config__n_estimators=500,config__reg_alpha=0.0001,config__reg_lambda=1.9153,config__subsample=0.7048\"\n  },\n  \"last_result_time\": 1753478060.186306,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.7066666666666668,\n      \"min\": 0.7066666666666668,\n      \"avg\": 0.7066666666666668,\n      \"last\": 0.7066666666666668,\n      \"last-5-avg\": 0.7066666666666668,\n      \"last-10-avg\": 0.7066666666666668\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3375,\n      \"min\": 0.3375,\n      \"avg\": 0.3375,\n      \"last\": 0.3375,\n      \"last-5-avg\": 0.3375,\n      \"last-10-avg\": 0.3375\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.6266558170318604,\n      \"min\": 0.6266558170318604,\n      \"avg\": 0.6266558170318604,\n      \"last\": 0.6266558170318604,\n      \"last-5-avg\": 0.6266558170318604,\n      \"last-10-avg\": 0.6266558170318604\n    },\n    \"time_total_s\": {\n      \"max\": 0.6266558170318604,\n      \"min\": 0.6266558170318604,\n      \"avg\": 0.6266558170318604,\n      \"last\": 0.6266558170318604,\n      \"last-5-avg\": 0.6266558170318604,\n      \"last-10-avg\": 0.6266558170318604\n    },\n    \"time_since_restore\": {\n      \"max\": 0.6266558170318604,\n      \"min\": 0.6266558170318604,\n      \"avg\": 0.6266558170318604,\n      \"last\": 0.6266558170318604,\n      \"last-5-avg\": 0.6266558170318604,\n      \"last-10-avg\": 0.6266558170318604\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089e36d069039de63f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089e36d069039de63f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999999999d53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999999999d53f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe40d9080000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe40d9080000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe40d9080000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe40d9080000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe40d9080000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe40d9080000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"3b07dcb9\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.010312543157245627,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.7431303483148766,\n    \"config__colsample_bytree\": 0.8618143449586635,\n    \"config__reg_alpha\": 0.045637984466362275,\n    \"config__reg_lambda\": 1.5701591734797824\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.010312543157245627,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.7431303483148766,\n    \"config__colsample_bytree\": 0.8618143449586635,\n    \"config__reg_alpha\": 0.045637984466362275,\n    \"config__reg_lambda\": 1.5701591734797824\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.010312543157245627,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.7431303483148766,\n    \"config__colsample_bytree\": 0.8618143449586635,\n    \"config__reg_alpha\": 0.045637984466362275,\n    \"config__reg_lambda\": 1.5701591734797824\n  },\n  \"experiment_tag\": \"6_config__colsample_bytree=0.8618,config__learning_rate=0.0103,config__max_depth=5,config__n_estimators=100,config__reg_alpha=0.0456,config__reg_lambda=1.5702,config__subsample=0.7431\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_3b07dcb9_6_config__colsample_bytree=0.8618,config__learning_rate=0.0103,config__max_depth=5,config__n_estimators=100,con_2025-07-25_17-14-23\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478065.631128,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.7066666666666668,\n    \"cod_accuracy\": 0.2875,\n    \"timestamp\": 1753478065,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3b07dcb9\",\n    \"date\": \"2025-07-25_17-14-25\",\n    \"time_this_iter_s\": 0.15230488777160645,\n    \"time_total_s\": 0.15230488777160645,\n    \"pid\": 46619,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 5,\n      \"config__learning_rate\": 0.010312543157245627,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.7431303483148766,\n      \"config__colsample_bytree\": 0.8618143449586635,\n      \"config__reg_alpha\": 0.045637984466362275,\n      \"config__reg_lambda\": 1.5701591734797824\n    },\n    \"time_since_restore\": 0.15230488777160645,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"6_config__colsample_bytree=0.8618,config__learning_rate=0.0103,config__max_depth=5,config__n_estimators=100,config__reg_alpha=0.0456,config__reg_lambda=1.5702,config__subsample=0.7431\"\n  },\n  \"last_result_time\": 1753478065.794338,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.7066666666666668,\n      \"min\": 0.7066666666666668,\n      \"avg\": 0.7066666666666668,\n      \"last\": 0.7066666666666668,\n      \"last-5-avg\": 0.7066666666666668,\n      \"last-10-avg\": 0.7066666666666668\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.2875,\n      \"min\": 0.2875,\n      \"avg\": 0.2875,\n      \"last\": 0.2875,\n      \"last-5-avg\": 0.2875,\n      \"last-10-avg\": 0.2875\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.15230488777160645,\n      \"min\": 0.15230488777160645,\n      \"avg\": 0.15230488777160645,\n      \"last\": 0.15230488777160645,\n      \"last-5-avg\": 0.15230488777160645,\n      \"last-10-avg\": 0.15230488777160645\n    },\n    \"time_total_s\": {\n      \"max\": 0.15230488777160645,\n      \"min\": 0.15230488777160645,\n      \"avg\": 0.15230488777160645,\n      \"last\": 0.15230488777160645,\n      \"last-5-avg\": 0.15230488777160645,\n      \"last-10-avg\": 0.15230488777160645\n    },\n    \"time_since_restore\": {\n      \"max\": 0.15230488777160645,\n      \"min\": 0.15230488777160645,\n      \"avg\": 0.15230488777160645,\n      \"last\": 0.15230488777160645,\n      \"last-5-avg\": 0.15230488777160645,\n      \"last-10-avg\": 0.15230488777160645\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089e36d069039de63f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089e36d069039de63f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666666666d23f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666666666d23f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc37eba00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc37eba00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc37eba00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc37eba00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc37eba00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc37eba00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"483cfbfb\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.2567021662023807,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.7009274319872113,\n    \"config__colsample_bytree\": 0.9823502852031549,\n    \"config__reg_alpha\": 0.08197297345806717,\n    \"config__reg_lambda\": 7.41093483002283\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.2567021662023807,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.7009274319872113,\n    \"config__colsample_bytree\": 0.9823502852031549,\n    \"config__reg_alpha\": 0.08197297345806717,\n    \"config__reg_lambda\": 7.41093483002283\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.2567021662023807,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.7009274319872113,\n    \"config__colsample_bytree\": 0.9823502852031549,\n    \"config__reg_alpha\": 0.08197297345806717,\n    \"config__reg_lambda\": 7.41093483002283\n  },\n  \"experiment_tag\": \"4_config__colsample_bytree=0.9824,config__learning_rate=0.2567,config__max_depth=3,config__n_estimators=100,config__reg_alpha=0.0820,config__reg_lambda=7.4109,config__subsample=0.7009\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_483cfbfb_4_config__colsample_bytree=0.9824,config__learning_rate=0.2567,config__max_depth=3,config__n_estimators=100,con_2025-07-25_17-14-19\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478061.592202,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.7333333333333334,\n    \"cod_accuracy\": 0.3625,\n    \"timestamp\": 1753478061,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"483cfbfb\",\n    \"date\": \"2025-07-25_17-14-21\",\n    \"time_this_iter_s\": 0.1424999237060547,\n    \"time_total_s\": 0.1424999237060547,\n    \"pid\": 46595,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 3,\n      \"config__learning_rate\": 0.2567021662023807,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.7009274319872113,\n      \"config__colsample_bytree\": 0.9823502852031549,\n      \"config__reg_alpha\": 0.08197297345806717,\n      \"config__reg_lambda\": 7.41093483002283\n    },\n    \"time_since_restore\": 0.1424999237060547,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"4_config__colsample_bytree=0.9824,config__learning_rate=0.2567,config__max_depth=3,config__n_estimators=100,config__reg_alpha=0.0820,config__reg_lambda=7.4109,config__subsample=0.7009\"\n  },\n  \"last_result_time\": 1753478061.7444422,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.7333333333333334,\n      \"min\": 0.7333333333333334,\n      \"avg\": 0.7333333333333334,\n      \"last\": 0.7333333333333334,\n      \"last-5-avg\": 0.7333333333333334,\n      \"last-10-avg\": 0.7333333333333334\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3625,\n      \"min\": 0.3625,\n      \"avg\": 0.3625,\n      \"last\": 0.3625,\n      \"last-5-avg\": 0.3625,\n      \"last-10-avg\": 0.3625\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.1424999237060547,\n      \"min\": 0.1424999237060547,\n      \"avg\": 0.1424999237060547,\n      \"last\": 0.1424999237060547,\n      \"last-5-avg\": 0.1424999237060547,\n      \"last-10-avg\": 0.1424999237060547\n    },\n    \"time_total_s\": {\n      \"max\": 0.1424999237060547,\n      \"min\": 0.1424999237060547,\n      \"avg\": 0.1424999237060547,\n      \"last\": 0.1424999237060547,\n      \"last-5-avg\": 0.1424999237060547,\n      \"last-10-avg\": 0.1424999237060547\n    },\n    \"time_since_restore\": {\n      \"max\": 0.1424999237060547,\n      \"min\": 0.1424999237060547,\n      \"avg\": 0.1424999237060547,\n      \"last\": 0.1424999237060547,\n      \"last-5-avg\": 0.1424999237060547,\n      \"last-10-avg\": 0.1424999237060547\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308787777777777e73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308787777777777e73f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333333333d73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333333333d73f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc23d7000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc23d7000000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc23d7000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc23d7000000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc23d7000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc23d7000000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"01a4b92a\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.11203664707494322,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.8947950247708606,\n    \"config__colsample_bytree\": 0.9874284837192544,\n    \"config__reg_alpha\": 0.008994454967874273,\n    \"config__reg_lambda\": 3.7248698570633447\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.11203664707494322,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.8947950247708606,\n    \"config__colsample_bytree\": 0.9874284837192544,\n    \"config__reg_alpha\": 0.008994454967874273,\n    \"config__reg_lambda\": 3.7248698570633447\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.11203664707494322,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.8947950247708606,\n    \"config__colsample_bytree\": 0.9874284837192544,\n    \"config__reg_alpha\": 0.008994454967874273,\n    \"config__reg_lambda\": 3.7248698570633447\n  },\n  \"experiment_tag\": \"5_config__colsample_bytree=0.9874,config__learning_rate=0.1120,config__max_depth=5,config__n_estimators=500,config__reg_alpha=0.0090,config__reg_lambda=3.7249,config__subsample=0.8948\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_01a4b92a_5_config__colsample_bytree=0.9874,config__learning_rate=0.1120,config__max_depth=5,config__n_estimators=500,con_2025-07-25_17-14-21\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478063.61209,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.76,\n    \"cod_accuracy\": 0.3625,\n    \"timestamp\": 1753478064,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"01a4b92a\",\n    \"date\": \"2025-07-25_17-14-24\",\n    \"time_this_iter_s\": 0.571599006652832,\n    \"time_total_s\": 0.571599006652832,\n    \"pid\": 46607,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 5,\n      \"config__learning_rate\": 0.11203664707494322,\n      \"config__n_estimators\": 500,\n      \"config__subsample\": 0.8947950247708606,\n      \"config__colsample_bytree\": 0.9874284837192544,\n      \"config__reg_alpha\": 0.008994454967874273,\n      \"config__reg_lambda\": 3.7248698570633447\n    },\n    \"time_since_restore\": 0.571599006652832,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"5_config__colsample_bytree=0.9874,config__learning_rate=0.1120,config__max_depth=5,config__n_estimators=500,config__reg_alpha=0.0090,config__reg_lambda=3.7249,config__subsample=0.8948\"\n  },\n  \"last_result_time\": 1753478064.196247,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.76,\n      \"min\": 0.76,\n      \"avg\": 0.76,\n      \"last\": 0.76,\n      \"last-5-avg\": 0.76,\n      \"last-10-avg\": 0.76\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3625,\n      \"min\": 0.3625,\n      \"avg\": 0.3625,\n      \"last\": 0.3625,\n      \"last-5-avg\": 0.3625,\n      \"last-10-avg\": 0.3625\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.571599006652832,\n      \"min\": 0.571599006652832,\n      \"avg\": 0.571599006652832,\n      \"last\": 0.571599006652832,\n      \"last-5-avg\": 0.571599006652832,\n      \"last-10-avg\": 0.571599006652832\n    },\n    \"time_total_s\": {\n      \"max\": 0.571599006652832,\n      \"min\": 0.571599006652832,\n      \"avg\": 0.571599006652832,\n      \"last\": 0.571599006652832,\n      \"last-5-avg\": 0.571599006652832,\n      \"last-10-avg\": 0.571599006652832\n    },\n    \"time_since_restore\": {\n      \"max\": 0.571599006652832,\n      \"min\": 0.571599006652832,\n      \"avg\": 0.571599006652832,\n      \"last\": 0.571599006652832,\n      \"last-5-avg\": 0.571599006652832,\n      \"last-10-avg\": 0.571599006652832\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430852b81e85eb51e83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430852b81e85eb51e83f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333333333d73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333333333d73f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe24a8a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe24a8a00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe24a8a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe24a8a00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe24a8a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe24a8a00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"ea33b6c5\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.16804374671159628,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9402068508977925,\n    \"config__colsample_bytree\": 0.7172374879717093,\n    \"config__reg_alpha\": 0.18807363585504888,\n    \"config__reg_lambda\": 2.6398199672340117\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.16804374671159628,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9402068508977925,\n    \"config__colsample_bytree\": 0.7172374879717093,\n    \"config__reg_alpha\": 0.18807363585504888,\n    \"config__reg_lambda\": 2.6398199672340117\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.16804374671159628,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9402068508977925,\n    \"config__colsample_bytree\": 0.7172374879717093,\n    \"config__reg_alpha\": 0.18807363585504888,\n    \"config__reg_lambda\": 2.6398199672340117\n  },\n  \"experiment_tag\": \"2_config__colsample_bytree=0.7172,config__learning_rate=0.1680,config__max_depth=5,config__n_estimators=100,config__reg_alpha=0.1881,config__reg_lambda=2.6398,config__subsample=0.9402\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_ea33b6c5_2_config__colsample_bytree=0.7172,config__learning_rate=0.1680,config__max_depth=5,config__n_estimators=100,con_2025-07-25_17-14-15\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478057.5516212,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.7333333333333334,\n    \"cod_accuracy\": 0.3375,\n    \"timestamp\": 1753478057,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ea33b6c5\",\n    \"date\": \"2025-07-25_17-14-17\",\n    \"time_this_iter_s\": 0.14989686012268066,\n    \"time_total_s\": 0.14989686012268066,\n    \"pid\": 46573,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 5,\n      \"config__learning_rate\": 0.16804374671159628,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.9402068508977925,\n      \"config__colsample_bytree\": 0.7172374879717093,\n      \"config__reg_alpha\": 0.18807363585504888,\n      \"config__reg_lambda\": 2.6398199672340117\n    },\n    \"time_since_restore\": 0.14989686012268066,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2_config__colsample_bytree=0.7172,config__learning_rate=0.1680,config__max_depth=5,config__n_estimators=100,config__reg_alpha=0.1881,config__reg_lambda=2.6398,config__subsample=0.9402\"\n  },\n  \"last_result_time\": 1753478057.7136571,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.7333333333333334,\n      \"min\": 0.7333333333333334,\n      \"avg\": 0.7333333333333334,\n      \"last\": 0.7333333333333334,\n      \"last-5-avg\": 0.7333333333333334,\n      \"last-10-avg\": 0.7333333333333334\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3375,\n      \"min\": 0.3375,\n      \"avg\": 0.3375,\n      \"last\": 0.3375,\n      \"last-5-avg\": 0.3375,\n      \"last-10-avg\": 0.3375\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.14989686012268066,\n      \"min\": 0.14989686012268066,\n      \"avg\": 0.14989686012268066,\n      \"last\": 0.14989686012268066,\n      \"last-5-avg\": 0.14989686012268066,\n      \"last-10-avg\": 0.14989686012268066\n    },\n    \"time_total_s\": {\n      \"max\": 0.14989686012268066,\n      \"min\": 0.14989686012268066,\n      \"avg\": 0.14989686012268066,\n      \"last\": 0.14989686012268066,\n      \"last-5-avg\": 0.14989686012268066,\n      \"last-10-avg\": 0.14989686012268066\n    },\n    \"time_since_restore\": {\n      \"max\": 0.14989686012268066,\n      \"min\": 0.14989686012268066,\n      \"avg\": 0.14989686012268066,\n      \"last\": 0.14989686012268066,\n      \"last-5-avg\": 0.14989686012268066,\n      \"last-10-avg\": 0.14989686012268066\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308787777777777e73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308787777777777e73f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999999999d53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999999999d53f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc32fd200000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc32fd200000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc32fd200000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc32fd200000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc32fd200000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc32fd200000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"fc26fd79\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.014642728229365264,\n    \"config__n_estimators\": 200,\n    \"config__subsample\": 0.7354569120907425,\n    \"config__colsample_bytree\": 0.8351446466711488,\n    \"config__reg_alpha\": 0.8436209906676196,\n    \"config__reg_lambda\": 2.4207885086680103\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.014642728229365264,\n    \"config__n_estimators\": 200,\n    \"config__subsample\": 0.7354569120907425,\n    \"config__colsample_bytree\": 0.8351446466711488,\n    \"config__reg_alpha\": 0.8436209906676196,\n    \"config__reg_lambda\": 2.4207885086680103\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.014642728229365264,\n    \"config__n_estimators\": 200,\n    \"config__subsample\": 0.7354569120907425,\n    \"config__colsample_bytree\": 0.8351446466711488,\n    \"config__reg_alpha\": 0.8436209906676196,\n    \"config__reg_lambda\": 2.4207885086680103\n  },\n  \"experiment_tag\": \"7_config__colsample_bytree=0.8351,config__learning_rate=0.0146,config__max_depth=10,config__n_estimators=200,config__reg_alpha=0.8436,config__reg_lambda=2.4208,config__subsample=0.7355\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_fc26fd79_7_config__colsample_bytree=0.8351,config__learning_rate=0.0146,config__max_depth=10,config__n_estimators=200,co_2025-07-25_17-14-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478067.630142,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.68,\n    \"cod_accuracy\": 0.275,\n    \"timestamp\": 1753478067,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"fc26fd79\",\n    \"date\": \"2025-07-25_17-14-27\",\n    \"time_this_iter_s\": 0.29587411880493164,\n    \"time_total_s\": 0.29587411880493164,\n    \"pid\": 46632,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 10,\n      \"config__learning_rate\": 0.014642728229365264,\n      \"config__n_estimators\": 200,\n      \"config__subsample\": 0.7354569120907425,\n      \"config__colsample_bytree\": 0.8351446466711488,\n      \"config__reg_alpha\": 0.8436209906676196,\n      \"config__reg_lambda\": 2.4207885086680103\n    },\n    \"time_since_restore\": 0.29587411880493164,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"7_config__colsample_bytree=0.8351,config__learning_rate=0.0146,config__max_depth=10,config__n_estimators=200,config__reg_alpha=0.8436,config__reg_lambda=2.4208,config__subsample=0.7355\"\n  },\n  \"last_result_time\": 1753478067.9371362,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.68,\n      \"min\": 0.68,\n      \"avg\": 0.68,\n      \"last\": 0.68,\n      \"last-5-avg\": 0.68,\n      \"last-10-avg\": 0.68\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.275,\n      \"min\": 0.275,\n      \"avg\": 0.275,\n      \"last\": 0.275,\n      \"last-5-avg\": 0.275,\n      \"last-10-avg\": 0.275\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.29587411880493164,\n      \"min\": 0.29587411880493164,\n      \"avg\": 0.29587411880493164,\n      \"last\": 0.29587411880493164,\n      \"last-5-avg\": 0.29587411880493164,\n      \"last-10-avg\": 0.29587411880493164\n    },\n    \"time_total_s\": {\n      \"max\": 0.29587411880493164,\n      \"min\": 0.29587411880493164,\n      \"avg\": 0.29587411880493164,\n      \"last\": 0.29587411880493164,\n      \"last-5-avg\": 0.29587411880493164,\n      \"last-10-avg\": 0.29587411880493164\n    },\n    \"time_since_restore\": {\n      \"max\": 0.29587411880493164,\n      \"min\": 0.29587411880493164,\n      \"avg\": 0.29587411880493164,\n      \"last\": 0.29587411880493164,\n      \"last-5-avg\": 0.29587411880493164,\n      \"last-10-avg\": 0.29587411880493164\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c3f5285c8fc2e53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c3f5285c8fc2e53f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999999999d13f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999999999d13f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd2ef9a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd2ef9a00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd2ef9a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd2ef9a00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd2ef9a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd2ef9a00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"60a5f80b\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.05941558983155261,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9564840063829776,\n    \"config__colsample_bytree\": 0.9583063399797321,\n    \"config__reg_alpha\": 0.00012348912039513633,\n    \"config__reg_lambda\": 1.166640388408883\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.05941558983155261,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9564840063829776,\n    \"config__colsample_bytree\": 0.9583063399797321,\n    \"config__reg_alpha\": 0.00012348912039513633,\n    \"config__reg_lambda\": 1.166640388408883\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.05941558983155261,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9564840063829776,\n    \"config__colsample_bytree\": 0.9583063399797321,\n    \"config__reg_alpha\": 0.00012348912039513633,\n    \"config__reg_lambda\": 1.166640388408883\n  },\n  \"experiment_tag\": \"8_config__colsample_bytree=0.9583,config__learning_rate=0.0594,config__max_depth=10,config__n_estimators=500,config__reg_alpha=0.0001,config__reg_lambda=1.1666,config__subsample=0.9565\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_60a5f80b_8_config__colsample_bytree=0.9583,config__learning_rate=0.0594,config__max_depth=10,config__n_estimators=500,co_2025-07-25_17-14-27\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478069.665385,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.7066666666666668,\n    \"cod_accuracy\": 0.35,\n    \"timestamp\": 1753478070,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"60a5f80b\",\n    \"date\": \"2025-07-25_17-14-30\",\n    \"time_this_iter_s\": 0.5619421005249023,\n    \"time_total_s\": 0.5619421005249023,\n    \"pid\": 46644,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 10,\n      \"config__learning_rate\": 0.05941558983155261,\n      \"config__n_estimators\": 500,\n      \"config__subsample\": 0.9564840063829776,\n      \"config__colsample_bytree\": 0.9583063399797321,\n      \"config__reg_alpha\": 0.00012348912039513633,\n      \"config__reg_lambda\": 1.166640388408883\n    },\n    \"time_since_restore\": 0.5619421005249023,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8_config__colsample_bytree=0.9583,config__learning_rate=0.0594,config__max_depth=10,config__n_estimators=500,config__reg_alpha=0.0001,config__reg_lambda=1.1666,config__subsample=0.9565\"\n  },\n  \"last_result_time\": 1753478070.232629,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.7066666666666668,\n      \"min\": 0.7066666666666668,\n      \"avg\": 0.7066666666666668,\n      \"last\": 0.7066666666666668,\n      \"last-5-avg\": 0.7066666666666668,\n      \"last-10-avg\": 0.7066666666666668\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.35,\n      \"min\": 0.35,\n      \"avg\": 0.35,\n      \"last\": 0.35,\n      \"last-5-avg\": 0.35,\n      \"last-10-avg\": 0.35\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.5619421005249023,\n      \"min\": 0.5619421005249023,\n      \"avg\": 0.5619421005249023,\n      \"last\": 0.5619421005249023,\n      \"last-5-avg\": 0.5619421005249023,\n      \"last-10-avg\": 0.5619421005249023\n    },\n    \"time_total_s\": {\n      \"max\": 0.5619421005249023,\n      \"min\": 0.5619421005249023,\n      \"avg\": 0.5619421005249023,\n      \"last\": 0.5619421005249023,\n      \"last-5-avg\": 0.5619421005249023,\n      \"last-10-avg\": 0.5619421005249023\n    },\n    \"time_since_restore\": {\n      \"max\": 0.5619421005249023,\n      \"min\": 0.5619421005249023,\n      \"avg\": 0.5619421005249023,\n      \"last\": 0.5619421005249023,\n      \"last-5-avg\": 0.5619421005249023,\n      \"last-10-avg\": 0.5619421005249023\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089e36d069039de63f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089e36d069039de63f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666666666d63f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666666666d63f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe1fb6e00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe1fb6e00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe1fb6e00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe1fb6e00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe1fb6e00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe1fb6e00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"72865353\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.012670148676859446,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.8697587562592671,\n    \"config__colsample_bytree\": 0.7120589930591322,\n    \"config__reg_alpha\": 0.0014599588443426337,\n    \"config__reg_lambda\": 5.429899121685774\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.012670148676859446,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.8697587562592671,\n    \"config__colsample_bytree\": 0.7120589930591322,\n    \"config__reg_alpha\": 0.0014599588443426337,\n    \"config__reg_lambda\": 5.429899121685774\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.012670148676859446,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.8697587562592671,\n    \"config__colsample_bytree\": 0.7120589930591322,\n    \"config__reg_alpha\": 0.0014599588443426337,\n    \"config__reg_lambda\": 5.429899121685774\n  },\n  \"experiment_tag\": \"10_config__colsample_bytree=0.7121,config__learning_rate=0.0127,config__max_depth=7,config__n_estimators=500,config__reg_alpha=0.0015,config__reg_lambda=5.4299,config__subsample=0.8698\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_72865353_10_config__colsample_bytree=0.7121,config__learning_rate=0.0127,config__max_depth=7,config__n_estimators=500,co_2025-07-25_17-14-31\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478073.666537,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.7200000000000001,\n    \"cod_accuracy\": 0.3125,\n    \"timestamp\": 1753478074,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"72865353\",\n    \"date\": \"2025-07-25_17-14-34\",\n    \"time_this_iter_s\": 0.6762759685516357,\n    \"time_total_s\": 0.6762759685516357,\n    \"pid\": 46668,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 7,\n      \"config__learning_rate\": 0.012670148676859446,\n      \"config__n_estimators\": 500,\n      \"config__subsample\": 0.8697587562592671,\n      \"config__colsample_bytree\": 0.7120589930591322,\n      \"config__reg_alpha\": 0.0014599588443426337,\n      \"config__reg_lambda\": 5.429899121685774\n    },\n    \"time_since_restore\": 0.6762759685516357,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10_config__colsample_bytree=0.7121,config__learning_rate=0.0127,config__max_depth=7,config__n_estimators=500,config__reg_alpha=0.0015,config__reg_lambda=5.4299,config__subsample=0.8698\"\n  },\n  \"last_result_time\": 1753478074.354165,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.7200000000000001,\n      \"min\": 0.7200000000000001,\n      \"avg\": 0.7200000000000001,\n      \"last\": 0.7200000000000001,\n      \"last-5-avg\": 0.7200000000000001,\n      \"last-10-avg\": 0.7200000000000001\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3125,\n      \"min\": 0.3125,\n      \"avg\": 0.3125,\n      \"last\": 0.3125,\n      \"last-5-avg\": 0.3125,\n      \"last-10-avg\": 0.3125\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.6762759685516357,\n      \"min\": 0.6762759685516357,\n      \"avg\": 0.6762759685516357,\n      \"last\": 0.6762759685516357,\n      \"last-5-avg\": 0.6762759685516357,\n      \"last-10-avg\": 0.6762759685516357\n    },\n    \"time_total_s\": {\n      \"max\": 0.6762759685516357,\n      \"min\": 0.6762759685516357,\n      \"avg\": 0.6762759685516357,\n      \"last\": 0.6762759685516357,\n      \"last-5-avg\": 0.6762759685516357,\n      \"last-10-avg\": 0.6762759685516357\n    },\n    \"time_since_restore\": {\n      \"max\": 0.6762759685516357,\n      \"min\": 0.6762759685516357,\n      \"avg\": 0.6762759685516357,\n      \"last\": 0.6762759685516357,\n      \"last-5-avg\": 0.6762759685516357,\n      \"last-10-avg\": 0.6762759685516357\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080bd7a3703d0ae73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080bd7a3703d0ae73f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000d43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000d43f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe5a40d80000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe5a40d80000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe5a40d80000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe5a40d80000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe5a40d80000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe5a40d80000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"727f6d52\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.15153424733643336,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.8494402997167428,\n    \"config__colsample_bytree\": 0.8327632154412701,\n    \"config__reg_alpha\": 0.36204511673361384,\n    \"config__reg_lambda\": 2.2828032753012173\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.15153424733643336,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.8494402997167428,\n    \"config__colsample_bytree\": 0.8327632154412701,\n    \"config__reg_alpha\": 0.36204511673361384,\n    \"config__reg_lambda\": 2.2828032753012173\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.15153424733643336,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.8494402997167428,\n    \"config__colsample_bytree\": 0.8327632154412701,\n    \"config__reg_alpha\": 0.36204511673361384,\n    \"config__reg_lambda\": 2.2828032753012173\n  },\n  \"experiment_tag\": \"9_config__colsample_bytree=0.8328,config__learning_rate=0.1515,config__max_depth=5,config__n_estimators=500,config__reg_alpha=0.3620,config__reg_lambda=2.2828,config__subsample=0.8494\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_727f6d52_9_config__colsample_bytree=0.8328,config__learning_rate=0.1515,config__max_depth=5,config__n_estimators=500,con_2025-07-25_17-14-29\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478071.644926,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.7200000000000001,\n    \"cod_accuracy\": 0.3375,\n    \"timestamp\": 1753478072,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"727f6d52\",\n    \"date\": \"2025-07-25_17-14-32\",\n    \"time_this_iter_s\": 0.5394430160522461,\n    \"time_total_s\": 0.5394430160522461,\n    \"pid\": 46656,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 5,\n      \"config__learning_rate\": 0.15153424733643336,\n      \"config__n_estimators\": 500,\n      \"config__subsample\": 0.8494402997167428,\n      \"config__colsample_bytree\": 0.8327632154412701,\n      \"config__reg_alpha\": 0.36204511673361384,\n      \"config__reg_lambda\": 2.2828032753012173\n    },\n    \"time_since_restore\": 0.5394430160522461,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"9_config__colsample_bytree=0.8328,config__learning_rate=0.1515,config__max_depth=5,config__n_estimators=500,config__reg_alpha=0.3620,config__reg_lambda=2.2828,config__subsample=0.8494\"\n  },\n  \"last_result_time\": 1753478072.1948428,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.7200000000000001,\n      \"min\": 0.7200000000000001,\n      \"avg\": 0.7200000000000001,\n      \"last\": 0.7200000000000001,\n      \"last-5-avg\": 0.7200000000000001,\n      \"last-10-avg\": 0.7200000000000001\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3375,\n      \"min\": 0.3375,\n      \"avg\": 0.3375,\n      \"last\": 0.3375,\n      \"last-5-avg\": 0.3375,\n      \"last-10-avg\": 0.3375\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.5394430160522461,\n      \"min\": 0.5394430160522461,\n      \"avg\": 0.5394430160522461,\n      \"last\": 0.5394430160522461,\n      \"last-5-avg\": 0.5394430160522461,\n      \"last-10-avg\": 0.5394430160522461\n    },\n    \"time_total_s\": {\n      \"max\": 0.5394430160522461,\n      \"min\": 0.5394430160522461,\n      \"avg\": 0.5394430160522461,\n      \"last\": 0.5394430160522461,\n      \"last-5-avg\": 0.5394430160522461,\n      \"last-10-avg\": 0.5394430160522461\n    },\n    \"time_since_restore\": {\n      \"max\": 0.5394430160522461,\n      \"min\": 0.5394430160522461,\n      \"avg\": 0.5394430160522461,\n      \"last\": 0.5394430160522461,\n      \"last-5-avg\": 0.5394430160522461,\n      \"last-10-avg\": 0.5394430160522461\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080bd7a3703d0ae73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080bd7a3703d0ae73f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999999999d53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999999999d53f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe1431e00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe1431e00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe1431e00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe1431e00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe1431e00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe1431e00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": 441964.01523325, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 1, "_metric": null, "_total_time": 7.947843551635742, "_iteration": 219, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1753478053.5188758, "_session_str": "2025-07-25_17-14-13", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f1000000000000008c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1753478053.5188758}}