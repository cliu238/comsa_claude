{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"c2bdf356\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005951d030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0e7867626f6f73745f74756e696e67948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f63326264663335365f315f636f6e6669675f5f636f6c73616d706c655f6279747265653d302e373739392c636f6e6669675f5f6c6561726e696e675f726174653d302e303133332c636f6e6669675f5f6d61785f64657074683d352c636f6e6669675f5f6e5f657374696d61746f72733d3130302c636f6e5f323032352d30372d32355f31372d32392d3334948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c3e2f55736572732f657269636c69752f70726f6a65637473352f636f6e746578742d656e67696e656572696e672d696e74726f2f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d30372d32355f31372d32392d33349475622e\"\n  },\n  \"config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.013276218958669317,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9909320924658009,\n    \"config__colsample_bytree\": 0.7799232827051151,\n    \"config__reg_alpha\": 0.8770848002570882,\n    \"config__reg_lambda\": 2.0176148282289335\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.013276218958669317,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9909320924658009,\n    \"config__colsample_bytree\": 0.7799232827051151,\n    \"config__reg_alpha\": 0.8770848002570882,\n    \"config__reg_lambda\": 2.0176148282289335\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.013276218958669317,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9909320924658009,\n    \"config__colsample_bytree\": 0.7799232827051151,\n    \"config__reg_alpha\": 0.8770848002570882,\n    \"config__reg_lambda\": 2.0176148282289335\n  },\n  \"experiment_tag\": \"1_config__colsample_bytree=0.7799,config__learning_rate=0.0133,config__max_depth=5,config__n_estimators=100,config__reg_alpha=0.8771,config__reg_lambda=2.0176,config__subsample=0.9909\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_c2bdf356_1_config__colsample_bytree=0.7799,config__learning_rate=0.0133,config__max_depth=5,config__n_estimators=100,con_2025-07-25_17-29-34\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478976.757222,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8219178082191781,\n    \"cod_accuracy\": 0.2875,\n    \"timestamp\": 1753478977,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"c2bdf356\",\n    \"date\": \"2025-07-25_17-29-37\",\n    \"time_this_iter_s\": 0.3085792064666748,\n    \"time_total_s\": 0.3085792064666748,\n    \"pid\": 52382,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 5,\n      \"config__learning_rate\": 0.013276218958669317,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.9909320924658009,\n      \"config__colsample_bytree\": 0.7799232827051151,\n      \"config__reg_alpha\": 0.8770848002570882,\n      \"config__reg_lambda\": 2.0176148282289335\n    },\n    \"time_since_restore\": 0.3085792064666748,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"1_config__colsample_bytree=0.7799,config__learning_rate=0.0133,config__max_depth=5,config__n_estimators=100,config__reg_alpha=0.8771,config__reg_lambda=2.0176,config__subsample=0.9909\"\n  },\n  \"last_result_time\": 1753478977.076706,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8219178082191781,\n      \"min\": 0.8219178082191781,\n      \"avg\": 0.8219178082191781,\n      \"last\": 0.8219178082191781,\n      \"last-5-avg\": 0.8219178082191781,\n      \"last-10-avg\": 0.8219178082191781\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.2875,\n      \"min\": 0.2875,\n      \"avg\": 0.2875,\n      \"last\": 0.2875,\n      \"last-5-avg\": 0.2875,\n      \"last-10-avg\": 0.2875\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.3085792064666748,\n      \"min\": 0.3085792064666748,\n      \"avg\": 0.3085792064666748,\n      \"last\": 0.3085792064666748,\n      \"last-5-avg\": 0.3085792064666748,\n      \"last-10-avg\": 0.3085792064666748\n    },\n    \"time_total_s\": {\n      \"max\": 0.3085792064666748,\n      \"min\": 0.3085792064666748,\n      \"avg\": 0.3085792064666748,\n      \"last\": 0.3085792064666748,\n      \"last-5-avg\": 0.3085792064666748,\n      \"last-10-avg\": 0.3085792064666748\n    },\n    \"time_since_restore\": {\n      \"max\": 0.3085792064666748,\n      \"min\": 0.3085792064666748,\n      \"avg\": 0.3085792064666748,\n      \"last\": 0.3085792064666748,\n      \"last-5-avg\": 0.3085792064666748,\n      \"last-10-avg\": 0.3085792064666748\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d3a44993264dea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d3a44993264dea3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666666666d23f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666666666d23f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd3bfc300000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd3bfc300000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd3bfc300000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd3bfc300000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd3bfc300000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd3bfc300000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"8a8794f3\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.06264089763728563,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9070325612885304,\n    \"config__colsample_bytree\": 0.713516370917838,\n    \"config__reg_alpha\": 0.022573057955885555,\n    \"config__reg_lambda\": 4.015205295249183\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.06264089763728563,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9070325612885304,\n    \"config__colsample_bytree\": 0.713516370917838,\n    \"config__reg_alpha\": 0.022573057955885555,\n    \"config__reg_lambda\": 4.015205295249183\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.06264089763728563,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9070325612885304,\n    \"config__colsample_bytree\": 0.713516370917838,\n    \"config__reg_alpha\": 0.022573057955885555,\n    \"config__reg_lambda\": 4.015205295249183\n  },\n  \"experiment_tag\": \"5_config__colsample_bytree=0.7135,config__learning_rate=0.0626,config__max_depth=7,config__n_estimators=100,config__reg_alpha=0.0226,config__reg_lambda=4.0152,config__subsample=0.9070\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_8a8794f3_5_config__colsample_bytree=0.7135,config__learning_rate=0.0626,config__max_depth=7,config__n_estimators=100,con_2025-07-25_17-29-43\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478985.005138,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.863013698630137,\n    \"cod_accuracy\": 0.3275,\n    \"timestamp\": 1753478985,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"8a8794f3\",\n    \"date\": \"2025-07-25_17-29-45\",\n    \"time_this_iter_s\": 0.3742687702178955,\n    \"time_total_s\": 0.3742687702178955,\n    \"pid\": 52437,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 7,\n      \"config__learning_rate\": 0.06264089763728563,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.9070325612885304,\n      \"config__colsample_bytree\": 0.713516370917838,\n      \"config__reg_alpha\": 0.022573057955885555,\n      \"config__reg_lambda\": 4.015205295249183\n    },\n    \"time_since_restore\": 0.3742687702178955,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"5_config__colsample_bytree=0.7135,config__learning_rate=0.0626,config__max_depth=7,config__n_estimators=100,config__reg_alpha=0.0226,config__reg_lambda=4.0152,config__subsample=0.9070\"\n  },\n  \"last_result_time\": 1753478985.391339,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.863013698630137,\n      \"min\": 0.863013698630137,\n      \"avg\": 0.863013698630137,\n      \"last\": 0.863013698630137,\n      \"last-5-avg\": 0.863013698630137,\n      \"last-10-avg\": 0.863013698630137\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3275,\n      \"min\": 0.3275,\n      \"avg\": 0.3275,\n      \"last\": 0.3275,\n      \"last-5-avg\": 0.3275,\n      \"last-10-avg\": 0.3275\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.3742687702178955,\n      \"min\": 0.3742687702178955,\n      \"avg\": 0.3742687702178955,\n      \"last\": 0.3742687702178955,\n      \"last-5-avg\": 0.3742687702178955,\n      \"last-10-avg\": 0.3742687702178955\n    },\n    \"time_total_s\": {\n      \"max\": 0.3742687702178955,\n      \"min\": 0.3742687702178955,\n      \"avg\": 0.3742687702178955,\n      \"last\": 0.3742687702178955,\n      \"last-5-avg\": 0.3742687702178955,\n      \"last-10-avg\": 0.3742687702178955\n    },\n    \"time_since_restore\": {\n      \"max\": 0.3742687702178955,\n      \"min\": 0.3742687702178955,\n      \"avg\": 0.3742687702178955,\n      \"last\": 0.3742687702178955,\n      \"last-5-avg\": 0.3742687702178955,\n      \"last-10-avg\": 0.3742687702178955\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ddb973e7ce9deb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ddb973e7ce9deb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f6285c8fc2f5d43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f6285c8fc2f5d43f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd7f40500000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd7f40500000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd7f40500000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd7f40500000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd7f40500000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd7f40500000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5dce83aa\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.028853313893727004,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9264573304275078,\n    \"config__colsample_bytree\": 0.7456214536275082,\n    \"config__reg_alpha\": 0.001803522705921707,\n    \"config__reg_lambda\": 1.8075962855407197\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.028853313893727004,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9264573304275078,\n    \"config__colsample_bytree\": 0.7456214536275082,\n    \"config__reg_alpha\": 0.001803522705921707,\n    \"config__reg_lambda\": 1.8075962855407197\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 5,\n    \"config__learning_rate\": 0.028853313893727004,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9264573304275078,\n    \"config__colsample_bytree\": 0.7456214536275082,\n    \"config__reg_alpha\": 0.001803522705921707,\n    \"config__reg_lambda\": 1.8075962855407197\n  },\n  \"experiment_tag\": \"3_config__colsample_bytree=0.7456,config__learning_rate=0.0289,config__max_depth=5,config__n_estimators=500,config__reg_alpha=0.0018,config__reg_lambda=1.8076,config__subsample=0.9265\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5dce83aa_3_config__colsample_bytree=0.7456,config__learning_rate=0.0289,config__max_depth=5,config__n_estimators=500,con_2025-07-25_17-29-38\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478980.848276,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8712328767123287,\n    \"cod_accuracy\": 0.33249999999999996,\n    \"timestamp\": 1753478982,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5dce83aa\",\n    \"date\": \"2025-07-25_17-29-42\",\n    \"time_this_iter_s\": 1.4001200199127197,\n    \"time_total_s\": 1.4001200199127197,\n    \"pid\": 52408,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 5,\n      \"config__learning_rate\": 0.028853313893727004,\n      \"config__n_estimators\": 500,\n      \"config__subsample\": 0.9264573304275078,\n      \"config__colsample_bytree\": 0.7456214536275082,\n      \"config__reg_alpha\": 0.001803522705921707,\n      \"config__reg_lambda\": 1.8075962855407197\n    },\n    \"time_since_restore\": 1.4001200199127197,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3_config__colsample_bytree=0.7456,config__learning_rate=0.0289,config__max_depth=5,config__n_estimators=500,config__reg_alpha=0.0018,config__reg_lambda=1.8076,config__subsample=0.9265\"\n  },\n  \"last_result_time\": 1753478982.260006,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8712328767123287,\n      \"min\": 0.8712328767123287,\n      \"avg\": 0.8712328767123287,\n      \"last\": 0.8712328767123287,\n      \"last-5-avg\": 0.8712328767123287,\n      \"last-10-avg\": 0.8712328767123287\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.33249999999999996,\n      \"min\": 0.33249999999999996,\n      \"avg\": 0.33249999999999996,\n      \"last\": 0.33249999999999996,\n      \"last-5-avg\": 0.33249999999999996,\n      \"last-10-avg\": 0.33249999999999996\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 1.4001200199127197,\n      \"min\": 1.4001200199127197,\n      \"avg\": 1.4001200199127197,\n      \"last\": 1.4001200199127197,\n      \"last-5-avg\": 1.4001200199127197,\n      \"last-10-avg\": 1.4001200199127197\n    },\n    \"time_total_s\": {\n      \"max\": 1.4001200199127197,\n      \"min\": 1.4001200199127197,\n      \"avg\": 1.4001200199127197,\n      \"last\": 1.4001200199127197,\n      \"last-5-avg\": 1.4001200199127197,\n      \"last-10-avg\": 1.4001200199127197\n    },\n    \"time_since_restore\": {\n      \"max\": 1.4001200199127197,\n      \"min\": 1.4001200199127197,\n      \"avg\": 1.4001200199127197,\n      \"last\": 1.4001200199127197,\n      \"last-5-avg\": 1.4001200199127197,\n      \"last-10-avg\": 1.4001200199127197\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430812be15c523e1eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430812be15c523e1eb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430847e17a14ae47d53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430847e17a14ae47d53f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff666e440000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff666e440000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff666e440000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff666e440000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff666e440000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff666e440000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"39ff9dbd\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059526040000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0e7867626f6f73745f74756e696e67948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f33396666396462645f325f636f6e6669675f5f636f6c73616d706c655f6279747265653d302e373837362c636f6e6669675f5f6c6561726e696e675f726174653d302e303233362c636f6e6669675f5f6d61785f64657074683d372c636f6e6669675f5f6e5f657374696d61746f72733d3230302c636f6e5f323032352d30372d32355f31372d32392d3336948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c3e2f55736572732f657269636c69752f70726f6a65637473352f636f6e746578742d656e67696e656572696e672d696e74726f2f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d649468008c125f75706c6f61645f746f5f66735f706174689493947d94288c0a6c6f63616c5f70617468948c6f2f746d702f7261792f73657373696f6e5f323032352d30372d32355f31372d32382d35315f3831383436355f35323036312f6172746966616374732f323032352d30372d32355f31372d32392d33342f7867626f6f73745f74756e696e672f6472697665725f617274696661637473948c02667394681b8c0766735f70617468948c4d2f55736572732f657269636c69752f70726f6a65637473352f636f6e746578742d656e67696e656572696e672d696e74726f2f7261795f726573756c74732f7867626f6f73745f74756e696e67948c076578636c756465944e75869475628c0a5f74696d657374616d70948c13323032352d30372d32355f31372d32392d33349475622e\"\n  },\n  \"config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.023610933830092367,\n    \"config__n_estimators\": 200,\n    \"config__subsample\": 0.8860786084505037,\n    \"config__colsample_bytree\": 0.7876130460268764,\n    \"config__reg_alpha\": 0.026756898711585663,\n    \"config__reg_lambda\": 1.7865581979035157\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.023610933830092367,\n    \"config__n_estimators\": 200,\n    \"config__subsample\": 0.8860786084505037,\n    \"config__colsample_bytree\": 0.7876130460268764,\n    \"config__reg_alpha\": 0.026756898711585663,\n    \"config__reg_lambda\": 1.7865581979035157\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.023610933830092367,\n    \"config__n_estimators\": 200,\n    \"config__subsample\": 0.8860786084505037,\n    \"config__colsample_bytree\": 0.7876130460268764,\n    \"config__reg_alpha\": 0.026756898711585663,\n    \"config__reg_lambda\": 1.7865581979035157\n  },\n  \"experiment_tag\": \"2_config__colsample_bytree=0.7876,config__learning_rate=0.0236,config__max_depth=7,config__n_estimators=200,config__reg_alpha=0.0268,config__reg_lambda=1.7866,config__subsample=0.8861\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_39ff9dbd_2_config__colsample_bytree=0.7876,config__learning_rate=0.0236,config__max_depth=7,config__n_estimators=200,con_2025-07-25_17-29-36\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478978.8077471,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8767123287671232,\n    \"cod_accuracy\": 0.335,\n    \"timestamp\": 1753478979,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"39ff9dbd\",\n    \"date\": \"2025-07-25_17-29-39\",\n    \"time_this_iter_s\": 0.7375209331512451,\n    \"time_total_s\": 0.7375209331512451,\n    \"pid\": 52396,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 7,\n      \"config__learning_rate\": 0.023610933830092367,\n      \"config__n_estimators\": 200,\n      \"config__subsample\": 0.8860786084505037,\n      \"config__colsample_bytree\": 0.7876130460268764,\n      \"config__reg_alpha\": 0.026756898711585663,\n      \"config__reg_lambda\": 1.7865581979035157\n    },\n    \"time_since_restore\": 0.7375209331512451,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2_config__colsample_bytree=0.7876,config__learning_rate=0.0236,config__max_depth=7,config__n_estimators=200,config__reg_alpha=0.0268,config__reg_lambda=1.7866,config__subsample=0.8861\"\n  },\n  \"last_result_time\": 1753478979.552093,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8767123287671232,\n      \"min\": 0.8767123287671232,\n      \"avg\": 0.8767123287671232,\n      \"last\": 0.8767123287671232,\n      \"last-5-avg\": 0.8767123287671232,\n      \"last-10-avg\": 0.8767123287671232\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.335,\n      \"min\": 0.335,\n      \"avg\": 0.335,\n      \"last\": 0.335,\n      \"last-5-avg\": 0.335,\n      \"last-10-avg\": 0.335\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.7375209331512451,\n      \"min\": 0.7375209331512451,\n      \"avg\": 0.7375209331512451,\n      \"last\": 0.7375209331512451,\n      \"last-5-avg\": 0.7375209331512451,\n      \"last-10-avg\": 0.7375209331512451\n    },\n    \"time_total_s\": {\n      \"max\": 0.7375209331512451,\n      \"min\": 0.7375209331512451,\n      \"avg\": 0.7375209331512451,\n      \"last\": 0.7375209331512451,\n      \"last-5-avg\": 0.7375209331512451,\n      \"last-10-avg\": 0.7375209331512451\n    },\n    \"time_since_restore\": {\n      \"max\": 0.7375209331512451,\n      \"min\": 0.7375209331512451,\n      \"avg\": 0.7375209331512451,\n      \"last\": 0.7375209331512451,\n      \"last-5-avg\": 0.7375209331512451,\n      \"last-10-avg\": 0.7375209331512451\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e0c08103070eec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e0c08103070eec3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308713d0ad7a370d53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308713d0ad7a370d53f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe799c580000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe799c580000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe799c580000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe799c580000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe799c580000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe799c580000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"08112a27\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.04271566110318521,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9463288944398203,\n    \"config__colsample_bytree\": 0.8825547348635896,\n    \"config__reg_alpha\": 0.00032085694204891723,\n    \"config__reg_lambda\": 6.1336300656441045\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.04271566110318521,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9463288944398203,\n    \"config__colsample_bytree\": 0.8825547348635896,\n    \"config__reg_alpha\": 0.00032085694204891723,\n    \"config__reg_lambda\": 6.1336300656441045\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.04271566110318521,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9463288944398203,\n    \"config__colsample_bytree\": 0.8825547348635896,\n    \"config__reg_alpha\": 0.00032085694204891723,\n    \"config__reg_lambda\": 6.1336300656441045\n  },\n  \"experiment_tag\": \"4_config__colsample_bytree=0.8826,config__learning_rate=0.0427,config__max_depth=10,config__n_estimators=500,config__reg_alpha=0.0003,config__reg_lambda=6.1336,config__subsample=0.9463\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_08112a27_4_config__colsample_bytree=0.8826,config__learning_rate=0.0427,config__max_depth=10,config__n_estimators=500,co_2025-07-25_17-29-40\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478983.016661,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8657534246575341,\n    \"cod_accuracy\": 0.31,\n    \"timestamp\": 1753478984,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"08112a27\",\n    \"date\": \"2025-07-25_17-29-44\",\n    \"time_this_iter_s\": 1.9030306339263916,\n    \"time_total_s\": 1.9030306339263916,\n    \"pid\": 52425,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 10,\n      \"config__learning_rate\": 0.04271566110318521,\n      \"config__n_estimators\": 500,\n      \"config__subsample\": 0.9463288944398203,\n      \"config__colsample_bytree\": 0.8825547348635896,\n      \"config__reg_alpha\": 0.00032085694204891723,\n      \"config__reg_lambda\": 6.1336300656441045\n    },\n    \"time_since_restore\": 1.9030306339263916,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"4_config__colsample_bytree=0.8826,config__learning_rate=0.0427,config__max_depth=10,config__n_estimators=500,config__reg_alpha=0.0003,config__reg_lambda=6.1336,config__subsample=0.9463\"\n  },\n  \"last_result_time\": 1753478984.927367,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8657534246575341,\n      \"min\": 0.8657534246575341,\n      \"avg\": 0.8657534246575341,\n      \"last\": 0.8657534246575341,\n      \"last-5-avg\": 0.8657534246575341,\n      \"last-10-avg\": 0.8657534246575341\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.31,\n      \"min\": 0.31,\n      \"avg\": 0.31,\n      \"last\": 0.31,\n      \"last-5-avg\": 0.31,\n      \"last-10-avg\": 0.31\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 1.9030306339263916,\n      \"min\": 1.9030306339263916,\n      \"avg\": 1.9030306339263916,\n      \"last\": 1.9030306339263916,\n      \"last-5-avg\": 1.9030306339263916,\n      \"last-10-avg\": 1.9030306339263916\n    },\n    \"time_total_s\": {\n      \"max\": 1.9030306339263916,\n      \"min\": 1.9030306339263916,\n      \"avg\": 1.9030306339263916,\n      \"last\": 1.9030306339263916,\n      \"last-5-avg\": 1.9030306339263916,\n      \"last-10-avg\": 1.9030306339263916\n    },\n    \"time_since_restore\": {\n      \"max\": 1.9030306339263916,\n      \"min\": 1.9030306339263916,\n      \"avg\": 1.9030306339263916,\n      \"last\": 1.9030306339263916,\n      \"last-5-avg\": 1.9030306339263916,\n      \"last-10-avg\": 1.9030306339263916\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430843bba98640b4eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430843bba98640b4eb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d7a3703d0ad7d33f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d7a3703d0ad7d33f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ffe72d040000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ffe72d040000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ffe72d040000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ffe72d040000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ffe72d040000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ffe72d040000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"ec037218\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.1374791826154402,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9991216790036879,\n    \"config__colsample_bytree\": 0.8205195791110466,\n    \"config__reg_alpha\": 0.038141697369707586,\n    \"config__reg_lambda\": 1.6125907485532487\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.1374791826154402,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9991216790036879,\n    \"config__colsample_bytree\": 0.8205195791110466,\n    \"config__reg_alpha\": 0.038141697369707586,\n    \"config__reg_lambda\": 1.6125907485532487\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.1374791826154402,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.9991216790036879,\n    \"config__colsample_bytree\": 0.8205195791110466,\n    \"config__reg_alpha\": 0.038141697369707586,\n    \"config__reg_lambda\": 1.6125907485532487\n  },\n  \"experiment_tag\": \"10_config__colsample_bytree=0.8205,config__learning_rate=0.1375,config__max_depth=10,config__n_estimators=500,config__reg_alpha=0.0381,config__reg_lambda=1.6126,config__subsample=0.9991\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_ec037218_10_config__colsample_bytree=0.8205,config__learning_rate=0.1375,config__max_depth=10,config__n_estimators=500,c_2025-07-25_17-29-53\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478995.1000059,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.863013698630137,\n    \"cod_accuracy\": 0.32,\n    \"timestamp\": 1753478996,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ec037218\",\n    \"date\": \"2025-07-25_17-29-56\",\n    \"time_this_iter_s\": 1.0866119861602783,\n    \"time_total_s\": 1.0866119861602783,\n    \"pid\": 52503,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 10,\n      \"config__learning_rate\": 0.1374791826154402,\n      \"config__n_estimators\": 500,\n      \"config__subsample\": 0.9991216790036879,\n      \"config__colsample_bytree\": 0.8205195791110466,\n      \"config__reg_alpha\": 0.038141697369707586,\n      \"config__reg_lambda\": 1.6125907485532487\n    },\n    \"time_since_restore\": 1.0866119861602783,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10_config__colsample_bytree=0.8205,config__learning_rate=0.1375,config__max_depth=10,config__n_estimators=500,config__reg_alpha=0.0381,config__reg_lambda=1.6126,config__subsample=0.9991\"\n  },\n  \"last_result_time\": 1753478996.201586,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.863013698630137,\n      \"min\": 0.863013698630137,\n      \"avg\": 0.863013698630137,\n      \"last\": 0.863013698630137,\n      \"last-5-avg\": 0.863013698630137,\n      \"last-10-avg\": 0.863013698630137\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.32,\n      \"min\": 0.32,\n      \"avg\": 0.32,\n      \"last\": 0.32,\n      \"last-5-avg\": 0.32,\n      \"last-10-avg\": 0.32\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 1.0866119861602783,\n      \"min\": 1.0866119861602783,\n      \"avg\": 1.0866119861602783,\n      \"last\": 1.0866119861602783,\n      \"last-5-avg\": 1.0866119861602783,\n      \"last-10-avg\": 1.0866119861602783\n    },\n    \"time_total_s\": {\n      \"max\": 1.0866119861602783,\n      \"min\": 1.0866119861602783,\n      \"avg\": 1.0866119861602783,\n      \"last\": 1.0866119861602783,\n      \"last-5-avg\": 1.0866119861602783,\n      \"last-10-avg\": 1.0866119861602783\n    },\n    \"time_since_restore\": {\n      \"max\": 1.0866119861602783,\n      \"min\": 1.0866119861602783,\n      \"avg\": 1.0866119861602783,\n      \"last\": 1.0866119861602783,\n      \"last-5-avg\": 1.0866119861602783,\n      \"last-10-avg\": 1.0866119861602783\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ddb973e7ce9deb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ddb973e7ce9deb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087b14ae47e17ad43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087b14ae47e17ad43f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff162c340000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff162c340000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff162c340000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff162c340000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff162c340000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff162c340000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"1f0a6930\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.04163871710462219,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.8696688171890082,\n    \"config__colsample_bytree\": 0.776571053813898,\n    \"config__reg_alpha\": 0.0006012353942134963,\n    \"config__reg_lambda\": 2.711872584493836\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.04163871710462219,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.8696688171890082,\n    \"config__colsample_bytree\": 0.776571053813898,\n    \"config__reg_alpha\": 0.0006012353942134963,\n    \"config__reg_lambda\": 2.711872584493836\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.04163871710462219,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.8696688171890082,\n    \"config__colsample_bytree\": 0.776571053813898,\n    \"config__reg_alpha\": 0.0006012353942134963,\n    \"config__reg_lambda\": 2.711872584493836\n  },\n  \"experiment_tag\": \"9_config__colsample_bytree=0.7766,config__learning_rate=0.0416,config__max_depth=3,config__n_estimators=100,config__reg_alpha=0.0006,config__reg_lambda=2.7119,config__subsample=0.8697\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_1f0a6930_9_config__colsample_bytree=0.7766,config__learning_rate=0.0416,config__max_depth=3,config__n_estimators=100,con_2025-07-25_17-29-50\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478993.063162,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8493150684931505,\n    \"cod_accuracy\": 0.30500000000000005,\n    \"timestamp\": 1753478993,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"1f0a6930\",\n    \"date\": \"2025-07-25_17-29-53\",\n    \"time_this_iter_s\": 0.21918892860412598,\n    \"time_total_s\": 0.21918892860412598,\n    \"pid\": 52491,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 3,\n      \"config__learning_rate\": 0.04163871710462219,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.8696688171890082,\n      \"config__colsample_bytree\": 0.776571053813898,\n      \"config__reg_alpha\": 0.0006012353942134963,\n      \"config__reg_lambda\": 2.711872584493836\n    },\n    \"time_since_restore\": 0.21918892860412598,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"9_config__colsample_bytree=0.7766,config__learning_rate=0.0416,config__max_depth=3,config__n_estimators=100,config__reg_alpha=0.0006,config__reg_lambda=2.7119,config__subsample=0.8697\"\n  },\n  \"last_result_time\": 1753478993.29215,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8493150684931505,\n      \"min\": 0.8493150684931505,\n      \"avg\": 0.8493150684931505,\n      \"last\": 0.8493150684931505,\n      \"last-5-avg\": 0.8493150684931505,\n      \"last-10-avg\": 0.8493150684931505\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.30500000000000005,\n      \"min\": 0.30500000000000005,\n      \"avg\": 0.30500000000000005,\n      \"last\": 0.30500000000000005,\n      \"last-5-avg\": 0.30500000000000005,\n      \"last-10-avg\": 0.30500000000000005\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.21918892860412598,\n      \"min\": 0.21918892860412598,\n      \"avg\": 0.21918892860412598,\n      \"last\": 0.21918892860412598,\n      \"last-5-avg\": 0.21918892860412598,\n      \"last-10-avg\": 0.21918892860412598\n    },\n    \"time_total_s\": {\n      \"max\": 0.21918892860412598,\n      \"min\": 0.21918892860412598,\n      \"avg\": 0.21918892860412598,\n      \"last\": 0.21918892860412598,\n      \"last-5-avg\": 0.21918892860412598,\n      \"last-10-avg\": 0.21918892860412598\n    },\n    \"time_since_restore\": {\n      \"max\": 0.21918892860412598,\n      \"min\": 0.21918892860412598,\n      \"avg\": 0.21918892860412598,\n      \"last\": 0.21918892860412598,\n      \"last-5-avg\": 0.21918892860412598,\n      \"last-10-avg\": 0.21918892860412598\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d8b265cb962deb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d8b265cb962deb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430886eb51b81e85d33f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430886eb51b81e85d33f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fcc0e6200000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fcc0e6200000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fcc0e6200000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fcc0e6200000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fcc0e6200000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fcc0e6200000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"46b04751\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.052100352316827296,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9159076922503402,\n    \"config__colsample_bytree\": 0.7741977314973685,\n    \"config__reg_alpha\": 0.32218655359189835,\n    \"config__reg_lambda\": 1.0569978119034493\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.052100352316827296,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9159076922503402,\n    \"config__colsample_bytree\": 0.7741977314973685,\n    \"config__reg_alpha\": 0.32218655359189835,\n    \"config__reg_lambda\": 1.0569978119034493\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 10,\n    \"config__learning_rate\": 0.052100352316827296,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9159076922503402,\n    \"config__colsample_bytree\": 0.7741977314973685,\n    \"config__reg_alpha\": 0.32218655359189835,\n    \"config__reg_lambda\": 1.0569978119034493\n  },\n  \"experiment_tag\": \"6_config__colsample_bytree=0.7742,config__learning_rate=0.0521,config__max_depth=10,config__n_estimators=100,config__reg_alpha=0.3222,config__reg_lambda=1.0570,config__subsample=0.9159\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_46b04751_6_config__colsample_bytree=0.7742,config__learning_rate=0.0521,config__max_depth=10,config__n_estimators=100,co_2025-07-25_17-29-45\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478986.911314,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8712328767123287,\n    \"cod_accuracy\": 0.3075,\n    \"timestamp\": 1753478987,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"46b04751\",\n    \"date\": \"2025-07-25_17-29-47\",\n    \"time_this_iter_s\": 0.42878293991088867,\n    \"time_total_s\": 0.42878293991088867,\n    \"pid\": 52454,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 10,\n      \"config__learning_rate\": 0.052100352316827296,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.9159076922503402,\n      \"config__colsample_bytree\": 0.7741977314973685,\n      \"config__reg_alpha\": 0.32218655359189835,\n      \"config__reg_lambda\": 1.0569978119034493\n    },\n    \"time_since_restore\": 0.42878293991088867,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"6_config__colsample_bytree=0.7742,config__learning_rate=0.0521,config__max_depth=10,config__n_estimators=100,config__reg_alpha=0.3222,config__reg_lambda=1.0570,config__subsample=0.9159\"\n  },\n  \"last_result_time\": 1753478987.349246,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8712328767123287,\n      \"min\": 0.8712328767123287,\n      \"avg\": 0.8712328767123287,\n      \"last\": 0.8712328767123287,\n      \"last-5-avg\": 0.8712328767123287,\n      \"last-10-avg\": 0.8712328767123287\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3075,\n      \"min\": 0.3075,\n      \"avg\": 0.3075,\n      \"last\": 0.3075,\n      \"last-5-avg\": 0.3075,\n      \"last-10-avg\": 0.3075\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.42878293991088867,\n      \"min\": 0.42878293991088867,\n      \"avg\": 0.42878293991088867,\n      \"last\": 0.42878293991088867,\n      \"last-5-avg\": 0.42878293991088867,\n      \"last-10-avg\": 0.42878293991088867\n    },\n    \"time_total_s\": {\n      \"max\": 0.42878293991088867,\n      \"min\": 0.42878293991088867,\n      \"avg\": 0.42878293991088867,\n      \"last\": 0.42878293991088867,\n      \"last-5-avg\": 0.42878293991088867,\n      \"last-10-avg\": 0.42878293991088867\n    },\n    \"time_since_restore\": {\n      \"max\": 0.42878293991088867,\n      \"min\": 0.42878293991088867,\n      \"avg\": 0.42878293991088867,\n      \"last\": 0.42878293991088867,\n      \"last-5-avg\": 0.42878293991088867,\n      \"last-10-avg\": 0.42878293991088867\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430812be15c523e1eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430812be15c523e1eb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ae47e17a14aed33f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ae47e17a14aed33f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdb712e00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdb712e00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdb712e00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdb712e00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdb712e00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdb712e00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"3a1706d4\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.0857687977899282,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.7998576106798505,\n    \"config__colsample_bytree\": 0.8189947807160234,\n    \"config__reg_alpha\": 0.24557636033346303,\n    \"config__reg_lambda\": 7.682377091853917\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.0857687977899282,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.7998576106798505,\n    \"config__colsample_bytree\": 0.8189947807160234,\n    \"config__reg_alpha\": 0.24557636033346303,\n    \"config__reg_lambda\": 7.682377091853917\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.0857687977899282,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.7998576106798505,\n    \"config__colsample_bytree\": 0.8189947807160234,\n    \"config__reg_alpha\": 0.24557636033346303,\n    \"config__reg_lambda\": 7.682377091853917\n  },\n  \"experiment_tag\": \"7_config__colsample_bytree=0.8190,config__learning_rate=0.0858,config__max_depth=3,config__n_estimators=100,config__reg_alpha=0.2456,config__reg_lambda=7.6824,config__subsample=0.7999\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_3a1706d4_7_config__colsample_bytree=0.8190,config__learning_rate=0.0858,config__max_depth=3,config__n_estimators=100,con_2025-07-25_17-29-46\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478988.898549,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8630136986301368,\n    \"cod_accuracy\": 0.3175,\n    \"timestamp\": 1753478989,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3a1706d4\",\n    \"date\": \"2025-07-25_17-29-49\",\n    \"time_this_iter_s\": 0.22315025329589844,\n    \"time_total_s\": 0.22315025329589844,\n    \"pid\": 52467,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 3,\n      \"config__learning_rate\": 0.0857687977899282,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.7998576106798505,\n      \"config__colsample_bytree\": 0.8189947807160234,\n      \"config__reg_alpha\": 0.24557636033346303,\n      \"config__reg_lambda\": 7.682377091853917\n    },\n    \"time_since_restore\": 0.22315025329589844,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"7_config__colsample_bytree=0.8190,config__learning_rate=0.0858,config__max_depth=3,config__n_estimators=100,config__reg_alpha=0.2456,config__reg_lambda=7.6824,config__subsample=0.7999\"\n  },\n  \"last_result_time\": 1753478989.132139,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8630136986301368,\n      \"min\": 0.8630136986301368,\n      \"avg\": 0.8630136986301368,\n      \"last\": 0.8630136986301368,\n      \"last-5-avg\": 0.8630136986301368,\n      \"last-10-avg\": 0.8630136986301368\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.3175,\n      \"min\": 0.3175,\n      \"avg\": 0.3175,\n      \"last\": 0.3175,\n      \"last-5-avg\": 0.3175,\n      \"last-10-avg\": 0.3175\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.22315025329589844,\n      \"min\": 0.22315025329589844,\n      \"avg\": 0.22315025329589844,\n      \"last\": 0.22315025329589844,\n      \"last-5-avg\": 0.22315025329589844,\n      \"last-10-avg\": 0.22315025329589844\n    },\n    \"time_total_s\": {\n      \"max\": 0.22315025329589844,\n      \"min\": 0.22315025329589844,\n      \"avg\": 0.22315025329589844,\n      \"last\": 0.22315025329589844,\n      \"last-5-avg\": 0.22315025329589844,\n      \"last-10-avg\": 0.22315025329589844\n    },\n    \"time_since_restore\": {\n      \"max\": 0.22315025329589844,\n      \"min\": 0.22315025329589844,\n      \"avg\": 0.22315025329589844,\n      \"last\": 0.22315025329589844,\n      \"last-5-avg\": 0.22315025329589844,\n      \"last-10-avg\": 0.22315025329589844\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308dbb973e7ce9deb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308dbb973e7ce9deb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430852b81e85eb51d43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430852b81e85eb51d43f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fcc903000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fcc903000000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fcc903000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fcc903000000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fcc903000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fcc903000000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"caf1de4e\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.13698731788240506,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.7142743442814053,\n    \"config__colsample_bytree\": 0.9457978847458134,\n    \"config__reg_alpha\": 0.00025958660122194887,\n    \"config__reg_lambda\": 3.2870063625350596\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.13698731788240506,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.7142743442814053,\n    \"config__colsample_bytree\": 0.9457978847458134,\n    \"config__reg_alpha\": 0.00025958660122194887,\n    \"config__reg_lambda\": 3.2870063625350596\n  },\n  \"evaluated_params\": {\n    \"config__max_depth\": 7,\n    \"config__learning_rate\": 0.13698731788240506,\n    \"config__n_estimators\": 500,\n    \"config__subsample\": 0.7142743442814053,\n    \"config__colsample_bytree\": 0.9457978847458134,\n    \"config__reg_alpha\": 0.00025958660122194887,\n    \"config__reg_lambda\": 3.2870063625350596\n  },\n  \"experiment_tag\": \"8_config__colsample_bytree=0.9458,config__learning_rate=0.1370,config__max_depth=7,config__n_estimators=500,config__reg_alpha=0.0003,config__reg_lambda=3.2870,config__subsample=0.7143\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_caf1de4e_8_config__colsample_bytree=0.9458,config__learning_rate=0.1370,config__max_depth=7,config__n_estimators=500,con_2025-07-25_17-29-48\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478990.89983,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8410958904109588,\n    \"cod_accuracy\": 0.31500000000000006,\n    \"timestamp\": 1753478992,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"caf1de4e\",\n    \"date\": \"2025-07-25_17-29-52\",\n    \"time_this_iter_s\": 1.1472902297973633,\n    \"time_total_s\": 1.1472902297973633,\n    \"pid\": 52479,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 7,\n      \"config__learning_rate\": 0.13698731788240506,\n      \"config__n_estimators\": 500,\n      \"config__subsample\": 0.7142743442814053,\n      \"config__colsample_bytree\": 0.9457978847458134,\n      \"config__reg_alpha\": 0.00025958660122194887,\n      \"config__reg_lambda\": 3.2870063625350596\n    },\n    \"time_since_restore\": 1.1472902297973633,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8_config__colsample_bytree=0.9458,config__learning_rate=0.1370,config__max_depth=7,config__n_estimators=500,config__reg_alpha=0.0003,config__reg_lambda=3.2870,config__subsample=0.7143\"\n  },\n  \"last_result_time\": 1753478992.058389,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8410958904109588,\n      \"min\": 0.8410958904109588,\n      \"avg\": 0.8410958904109588,\n      \"last\": 0.8410958904109588,\n      \"last-5-avg\": 0.8410958904109588,\n      \"last-10-avg\": 0.8410958904109588\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.31500000000000006,\n      \"min\": 0.31500000000000006,\n      \"avg\": 0.31500000000000006,\n      \"last\": 0.31500000000000006,\n      \"last-5-avg\": 0.31500000000000006,\n      \"last-10-avg\": 0.31500000000000006\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 1.1472902297973633,\n      \"min\": 1.1472902297973633,\n      \"avg\": 1.1472902297973633,\n      \"last\": 1.1472902297973633,\n      \"last-5-avg\": 1.1472902297973633,\n      \"last-10-avg\": 1.1472902297973633\n    },\n    \"time_total_s\": {\n      \"max\": 1.1472902297973633,\n      \"min\": 1.1472902297973633,\n      \"avg\": 1.1472902297973633,\n      \"last\": 1.1472902297973633,\n      \"last-5-avg\": 1.1472902297973633,\n      \"last-10-avg\": 1.1472902297973633\n    },\n    \"time_since_restore\": {\n      \"max\": 1.1472902297973633,\n      \"min\": 1.1472902297973633,\n      \"avg\": 1.1472902297973633,\n      \"last\": 1.1472902297973633,\n      \"last-5-avg\": 1.1472902297973633,\n      \"last-10-avg\": 1.1472902297973633\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a3aec3ed41eaea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a3aec3ed41eaea3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a5c8fc2f528d43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a5c8fc2f528d43f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff25b4d00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff25b4d00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff25b4d00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff25b4d00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff25b4d00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff25b4d00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": 442885.307789166, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 1, "_metric": null, "_total_time": 15.657087802886963, "_iteration": 226, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1753478974.728294, "_session_str": "2025-07-25_17-29-34", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f1000000000000008c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1753478974.728294}}