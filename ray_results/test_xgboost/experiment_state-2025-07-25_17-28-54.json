{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5d57e_00000\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005951b030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0c746573745f7867626f6f7374948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35643537655f30303030305f305f636f6e6669675f5f636f6c73616d706c655f6279747265653d302e373335382c636f6e6669675f5f6c6561726e696e675f726174653d302e313734372c636f6e6669675f5f7265675f616c7068613d302e303030312c636f6e6669675f5f7265675f6c616d6264613d325f323032352d30372d32355f31372d32382d3534948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c3e2f55736572732f657269636c69752f70726f6a65637473352f636f6e746578742d656e67696e656572696e672d696e74726f2f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d30372d32355f31372d32382d35349475622e\"\n  },\n  \"config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.17467285081636735,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9869819840947571,\n    \"config__colsample_bytree\": 0.7358094784658741,\n    \"config__reg_alpha\": 0.00013472458674719921,\n    \"config__reg_lambda\": 2.7620149315170064\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.17467285081636735,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9869819840947571,\n    \"config__colsample_bytree\": 0.7358094784658741,\n    \"config__reg_alpha\": 0.00013472458674719921,\n    \"config__reg_lambda\": 2.7620149315170064\n  },\n  \"evaluated_params\": {\n    \"config__learning_rate\": 0.17467285081636735,\n    \"config__subsample\": 0.9869819840947571,\n    \"config__colsample_bytree\": 0.7358094784658741,\n    \"config__reg_alpha\": 0.00013472458674719921,\n    \"config__reg_lambda\": 2.7620149315170064\n  },\n  \"experiment_tag\": \"0_config__colsample_bytree=0.7358,config__learning_rate=0.1747,config__reg_alpha=0.0001,config__reg_lambda=2.7620,config__subsample=0.9870\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5d57e_00000_0_config__colsample_bytree=0.7358,config__learning_rate=0.1747,config__reg_alpha=0.0001,config__reg_lambda=2_2025-07-25_17-28-54\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478936.365191,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8539367181751287,\n    \"cod_accuracy\": 0.31599451699011616,\n    \"timestamp\": 1753478936,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5d57e_00000\",\n    \"date\": \"2025-07-25_17-28-56\",\n    \"time_this_iter_s\": 0.13179707527160645,\n    \"time_total_s\": 0.13179707527160645,\n    \"pid\": 52101,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 3,\n      \"config__learning_rate\": 0.17467285081636735,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.9869819840947571,\n      \"config__colsample_bytree\": 0.7358094784658741,\n      \"config__reg_alpha\": 0.00013472458674719921,\n      \"config__reg_lambda\": 2.7620149315170064\n    },\n    \"time_since_restore\": 0.13179707527160645,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"0_config__colsample_bytree=0.7358,config__learning_rate=0.1747,config__reg_alpha=0.0001,config__reg_lambda=2.7620,config__subsample=0.9870\"\n  },\n  \"last_result_time\": 1753478936.5156422,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8539367181751287,\n      \"min\": 0.8539367181751287,\n      \"avg\": 0.8539367181751287,\n      \"last\": 0.8539367181751287,\n      \"last-5-avg\": 0.8539367181751287,\n      \"last-10-avg\": 0.8539367181751287\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.31599451699011616,\n      \"min\": 0.31599451699011616,\n      \"avg\": 0.31599451699011616,\n      \"last\": 0.31599451699011616,\n      \"last-5-avg\": 0.31599451699011616,\n      \"last-10-avg\": 0.31599451699011616\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.13179707527160645,\n      \"min\": 0.13179707527160645,\n      \"avg\": 0.13179707527160645,\n      \"last\": 0.13179707527160645,\n      \"last-5-avg\": 0.13179707527160645,\n      \"last-10-avg\": 0.13179707527160645\n    },\n    \"time_total_s\": {\n      \"max\": 0.13179707527160645,\n      \"min\": 0.13179707527160645,\n      \"avg\": 0.13179707527160645,\n      \"last\": 0.13179707527160645,\n      \"last-5-avg\": 0.13179707527160645,\n      \"last-10-avg\": 0.13179707527160645\n    },\n    \"time_since_restore\": {\n      \"max\": 0.13179707527160645,\n      \"min\": 0.13179707527160645,\n      \"avg\": 0.13179707527160645,\n      \"last\": 0.13179707527160645,\n      \"last-5-avg\": 0.13179707527160645,\n      \"last-10-avg\": 0.13179707527160645\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cc4dad187353eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cc4dad187353eb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fc050c114139d43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fc050c114139d43f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc0deba00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc0deba00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc0deba00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc0deba00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc0deba00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc0deba00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5d57e_00001\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005951b030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0c746573745f7867626f6f7374948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35643537655f30303030315f315f636f6e6669675f5f636f6c73616d706c655f6279747265653d302e393430362c636f6e6669675f5f6c6561726e696e675f726174653d302e303435322c636f6e6669675f5f7265675f616c7068613d302e343633332c636f6e6669675f5f7265675f6c616d6264613d395f323032352d30372d32355f31372d32382d3534948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c3e2f55736572732f657269636c69752f70726f6a65637473352f636f6e746578742d656e67696e656572696e672d696e74726f2f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d30372d32355f31372d32382d35349475622e\"\n  },\n  \"config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.04520097641995165,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.832436023328144,\n    \"config__colsample_bytree\": 0.9406383315201772,\n    \"config__reg_alpha\": 0.4632828492504245,\n    \"config__reg_lambda\": 9.248150681143132\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.04520097641995165,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.832436023328144,\n    \"config__colsample_bytree\": 0.9406383315201772,\n    \"config__reg_alpha\": 0.4632828492504245,\n    \"config__reg_lambda\": 9.248150681143132\n  },\n  \"evaluated_params\": {\n    \"config__learning_rate\": 0.04520097641995165,\n    \"config__subsample\": 0.832436023328144,\n    \"config__colsample_bytree\": 0.9406383315201772,\n    \"config__reg_alpha\": 0.4632828492504245,\n    \"config__reg_lambda\": 9.248150681143132\n  },\n  \"experiment_tag\": \"1_config__colsample_bytree=0.9406,config__learning_rate=0.0452,config__reg_alpha=0.4633,config__reg_lambda=9.2482,config__subsample=0.8324\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5d57e_00001_1_config__colsample_bytree=0.9406,config__learning_rate=0.0452,config__reg_alpha=0.4633,config__reg_lambda=9_2025-07-25_17-28-54\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478936.3765619,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8649889624724061,\n    \"cod_accuracy\": 0.25205011663420146,\n    \"timestamp\": 1753478936,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5d57e_00001\",\n    \"date\": \"2025-07-25_17-28-56\",\n    \"time_this_iter_s\": 0.15848278999328613,\n    \"time_total_s\": 0.15848278999328613,\n    \"pid\": 52102,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 3,\n      \"config__learning_rate\": 0.04520097641995165,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.832436023328144,\n      \"config__colsample_bytree\": 0.9406383315201772,\n      \"config__reg_alpha\": 0.4632828492504245,\n      \"config__reg_lambda\": 9.248150681143132\n    },\n    \"time_since_restore\": 0.15848278999328613,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"1_config__colsample_bytree=0.9406,config__learning_rate=0.0452,config__reg_alpha=0.4633,config__reg_lambda=9.2482,config__subsample=0.8324\"\n  },\n  \"last_result_time\": 1753478936.550334,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8649889624724061,\n      \"min\": 0.8649889624724061,\n      \"avg\": 0.8649889624724061,\n      \"last\": 0.8649889624724061,\n      \"last-5-avg\": 0.8649889624724061,\n      \"last-10-avg\": 0.8649889624724061\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.25205011663420146,\n      \"min\": 0.25205011663420146,\n      \"avg\": 0.25205011663420146,\n      \"last\": 0.25205011663420146,\n      \"last-5-avg\": 0.25205011663420146,\n      \"last-10-avg\": 0.25205011663420146\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.15848278999328613,\n      \"min\": 0.15848278999328613,\n      \"avg\": 0.15848278999328613,\n      \"last\": 0.15848278999328613,\n      \"last-5-avg\": 0.15848278999328613,\n      \"last-10-avg\": 0.15848278999328613\n    },\n    \"time_total_s\": {\n      \"max\": 0.15848278999328613,\n      \"min\": 0.15848278999328613,\n      \"avg\": 0.15848278999328613,\n      \"last\": 0.15848278999328613,\n      \"last-5-avg\": 0.15848278999328613,\n      \"last-10-avg\": 0.15848278999328613\n    },\n    \"time_since_restore\": {\n      \"max\": 0.15848278999328613,\n      \"min\": 0.15848278999328613,\n      \"avg\": 0.15848278999328613,\n      \"last\": 0.15848278999328613,\n      \"last-5-avg\": 0.15848278999328613,\n      \"last-10-avg\": 0.15848278999328613\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e0092755fdadeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e0092755fdadeb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087f66f9cf9621d03f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087f66f9cf9621d03f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc4492a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc4492a00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc4492a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc4492a00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc4492a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc4492a00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5d57e_00003\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.01613478280978787,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.8705060385251359,\n    \"config__colsample_bytree\": 0.8018026899200852,\n    \"config__reg_alpha\": 0.003450499358484757,\n    \"config__reg_lambda\": 6.003201777206582\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.01613478280978787,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.8705060385251359,\n    \"config__colsample_bytree\": 0.8018026899200852,\n    \"config__reg_alpha\": 0.003450499358484757,\n    \"config__reg_lambda\": 6.003201777206582\n  },\n  \"evaluated_params\": {\n    \"config__learning_rate\": 0.01613478280978787,\n    \"config__subsample\": 0.8705060385251359,\n    \"config__colsample_bytree\": 0.8018026899200852,\n    \"config__reg_alpha\": 0.003450499358484757,\n    \"config__reg_lambda\": 6.003201777206582\n  },\n  \"experiment_tag\": \"3_config__colsample_bytree=0.8018,config__learning_rate=0.0161,config__reg_alpha=0.0035,config__reg_lambda=6.0032,config__subsample=0.8705\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5d57e_00003_3_config__colsample_bytree=0.8018,config__learning_rate=0.0161,config__reg_alpha=0.0035,config__reg_lambda=6_2025-07-25_17-28-56\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478938.7681012,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8650036791758646,\n    \"cod_accuracy\": 0.24603804439314145,\n    \"timestamp\": 1753478938,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5d57e_00003\",\n    \"date\": \"2025-07-25_17-28-58\",\n    \"time_this_iter_s\": 0.1558678150177002,\n    \"time_total_s\": 0.1558678150177002,\n    \"pid\": 52114,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 3,\n      \"config__learning_rate\": 0.01613478280978787,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.8705060385251359,\n      \"config__colsample_bytree\": 0.8018026899200852,\n      \"config__reg_alpha\": 0.003450499358484757,\n      \"config__reg_lambda\": 6.003201777206582\n    },\n    \"time_since_restore\": 0.1558678150177002,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3_config__colsample_bytree=0.8018,config__learning_rate=0.0161,config__reg_alpha=0.0035,config__reg_lambda=6.0032,config__subsample=0.8705\"\n  },\n  \"last_result_time\": 1753478938.955105,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8650036791758646,\n      \"min\": 0.8650036791758646,\n      \"avg\": 0.8650036791758646,\n      \"last\": 0.8650036791758646,\n      \"last-5-avg\": 0.8650036791758646,\n      \"last-10-avg\": 0.8650036791758646\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.24603804439314145,\n      \"min\": 0.24603804439314145,\n      \"avg\": 0.24603804439314145,\n      \"last\": 0.24603804439314145,\n      \"last-5-avg\": 0.24603804439314145,\n      \"last-10-avg\": 0.24603804439314145\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.1558678150177002,\n      \"min\": 0.1558678150177002,\n      \"avg\": 0.1558678150177002,\n      \"last\": 0.1558678150177002,\n      \"last-5-avg\": 0.1558678150177002,\n      \"last-10-avg\": 0.1558678150177002\n    },\n    \"time_total_s\": {\n      \"max\": 0.1558678150177002,\n      \"min\": 0.1558678150177002,\n      \"avg\": 0.1558678150177002,\n      \"last\": 0.1558678150177002,\n      \"last-5-avg\": 0.1558678150177002,\n      \"last-10-avg\": 0.1558678150177002\n    },\n    \"time_since_restore\": {\n      \"max\": 0.1558678150177002,\n      \"min\": 0.1558678150177002,\n      \"avg\": 0.1558678150177002,\n      \"last\": 0.1558678150177002,\n      \"last-5-avg\": 0.1558678150177002,\n      \"last-10-avg\": 0.1558678150177002\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308485c1f321caeeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308485c1f321caeeb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086bc31eb52c7ecf3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086bc31eb52c7ecf3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc3f37a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc3f37a00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc3f37a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc3f37a00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc3f37a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc3f37a00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5d57e_00002\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.12352389420833414,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9631641166027642,\n    \"config__colsample_bytree\": 0.9697280292745519,\n    \"config__reg_alpha\": 0.07835146557829091,\n    \"config__reg_lambda\": 8.802636822389262\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.12352389420833414,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.9631641166027642,\n    \"config__colsample_bytree\": 0.9697280292745519,\n    \"config__reg_alpha\": 0.07835146557829091,\n    \"config__reg_lambda\": 8.802636822389262\n  },\n  \"evaluated_params\": {\n    \"config__learning_rate\": 0.12352389420833414,\n    \"config__subsample\": 0.9631641166027642,\n    \"config__colsample_bytree\": 0.9697280292745519,\n    \"config__reg_alpha\": 0.07835146557829091,\n    \"config__reg_lambda\": 8.802636822389262\n  },\n  \"experiment_tag\": \"2_config__colsample_bytree=0.9697,config__learning_rate=0.1235,config__reg_alpha=0.0784,config__reg_lambda=8.8026,config__subsample=0.9632\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5d57e_00002_2_config__colsample_bytree=0.9697,config__learning_rate=0.1235,config__reg_alpha=0.0784,config__reg_lambda=8_2025-07-25_17-28-56\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478938.753402,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8849448123620309,\n    \"cod_accuracy\": 0.28205035711709114,\n    \"timestamp\": 1753478938,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5d57e_00002\",\n    \"date\": \"2025-07-25_17-28-58\",\n    \"time_this_iter_s\": 0.15150022506713867,\n    \"time_total_s\": 0.15150022506713867,\n    \"pid\": 52115,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 3,\n      \"config__learning_rate\": 0.12352389420833414,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.9631641166027642,\n      \"config__colsample_bytree\": 0.9697280292745519,\n      \"config__reg_alpha\": 0.07835146557829091,\n      \"config__reg_lambda\": 8.802636822389262\n    },\n    \"time_since_restore\": 0.15150022506713867,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2_config__colsample_bytree=0.9697,config__learning_rate=0.1235,config__reg_alpha=0.0784,config__reg_lambda=8.8026,config__subsample=0.9632\"\n  },\n  \"last_result_time\": 1753478938.913949,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8849448123620309,\n      \"min\": 0.8849448123620309,\n      \"avg\": 0.8849448123620309,\n      \"last\": 0.8849448123620309,\n      \"last-5-avg\": 0.8849448123620309,\n      \"last-10-avg\": 0.8849448123620309\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.28205035711709114,\n      \"min\": 0.28205035711709114,\n      \"avg\": 0.28205035711709114,\n      \"last\": 0.28205035711709114,\n      \"last-5-avg\": 0.28205035711709114,\n      \"last-10-avg\": 0.28205035711709114\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.15150022506713867,\n      \"min\": 0.15150022506713867,\n      \"avg\": 0.15150022506713867,\n      \"last\": 0.15150022506713867,\n      \"last-5-avg\": 0.15150022506713867,\n      \"last-10-avg\": 0.15150022506713867\n    },\n    \"time_total_s\": {\n      \"max\": 0.15150022506713867,\n      \"min\": 0.15150022506713867,\n      \"avg\": 0.15150022506713867,\n      \"last\": 0.15150022506713867,\n      \"last-5-avg\": 0.15150022506713867,\n      \"last-10-avg\": 0.15150022506713867\n    },\n    \"time_since_restore\": {\n      \"max\": 0.15150022506713867,\n      \"min\": 0.15150022506713867,\n      \"avg\": 0.15150022506713867,\n      \"last\": 0.15150022506713867,\n      \"last-5-avg\": 0.15150022506713867,\n      \"last-10-avg\": 0.15150022506713867\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430850837bc87751ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430850837bc87751ec3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085c27e9f01c0dd23f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085c27e9f01c0dd23f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc3645c00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc3645c00000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc3645c00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc3645c00000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc3645c00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc3645c00000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5d57e_00004\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059520040000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0c746573745f7867626f6f7374948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35643537655f30303030345f345f636f6e6669675f5f636f6c73616d706c655f6279747265653d302e393137382c636f6e6669675f5f6c6561726e696e675f726174653d302e303833322c636f6e6669675f5f7265675f616c7068613d302e303030312c636f6e6669675f5f7265675f6c616d6264613d335f323032352d30372d32355f31372d32382d3538948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c3e2f55736572732f657269636c69752f70726f6a65637473352f636f6e746578742d656e67696e656572696e672d696e74726f2f7261795f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d649468008c125f75706c6f61645f746f5f66735f706174689493947d94288c0a6c6f63616c5f70617468948c6d2f746d702f7261792f73657373696f6e5f323032352d30372d32355f31372d32382d35315f3831383436355f35323036312f6172746966616374732f323032352d30372d32355f31372d32382d35342f746573745f7867626f6f73742f6472697665725f617274696661637473948c02667394681b8c0766735f70617468948c4b2f55736572732f657269636c69752f70726f6a65637473352f636f6e746578742d656e67696e656572696e672d696e74726f2f7261795f726573756c74732f746573745f7867626f6f7374948c076578636c756465944e75869475628c0a5f74696d657374616d70948c13323032352d30372d32355f31372d32382d35349475622e\"\n  },\n  \"config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.08320435891144522,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.8255417339851507,\n    \"config__colsample_bytree\": 0.9177845354813994,\n    \"config__reg_alpha\": 0.0001136533273020187,\n    \"config__reg_lambda\": 3.9097980073805694\n  },\n  \"_Trial__unresolved_config\": {\n    \"config__max_depth\": 3,\n    \"config__learning_rate\": 0.08320435891144522,\n    \"config__n_estimators\": 100,\n    \"config__subsample\": 0.8255417339851507,\n    \"config__colsample_bytree\": 0.9177845354813994,\n    \"config__reg_alpha\": 0.0001136533273020187,\n    \"config__reg_lambda\": 3.9097980073805694\n  },\n  \"evaluated_params\": {\n    \"config__learning_rate\": 0.08320435891144522,\n    \"config__subsample\": 0.8255417339851507,\n    \"config__colsample_bytree\": 0.9177845354813994,\n    \"config__reg_alpha\": 0.0001136533273020187,\n    \"config__reg_lambda\": 3.9097980073805694\n  },\n  \"experiment_tag\": \"4_config__colsample_bytree=0.9178,config__learning_rate=0.0832,config__reg_alpha=0.0001,config__reg_lambda=3.9098,config__subsample=0.8255\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5d57e_00004_4_config__colsample_bytree=0.9178,config__learning_rate=0.0832,config__reg_alpha=0.0001,config__reg_lambda=3_2025-07-25_17-28-58\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1753478940.9700139,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"csmf_accuracy\": 0.8650036791758646,\n    \"cod_accuracy\": 0.26403818868287515,\n    \"timestamp\": 1753478941,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5d57e_00004\",\n    \"date\": \"2025-07-25_17-29-01\",\n    \"time_this_iter_s\": 0.14002108573913574,\n    \"time_total_s\": 0.14002108573913574,\n    \"pid\": 52128,\n    \"hostname\": \"wse-dsai-ggp67pg757.win.ad.jhu.edu\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"config__max_depth\": 3,\n      \"config__learning_rate\": 0.08320435891144522,\n      \"config__n_estimators\": 100,\n      \"config__subsample\": 0.8255417339851507,\n      \"config__colsample_bytree\": 0.9177845354813994,\n      \"config__reg_alpha\": 0.0001136533273020187,\n      \"config__reg_lambda\": 3.9097980073805694\n    },\n    \"time_since_restore\": 0.14002108573913574,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"4_config__colsample_bytree=0.9178,config__learning_rate=0.0832,config__reg_alpha=0.0001,config__reg_lambda=3.9098,config__subsample=0.8255\"\n  },\n  \"last_result_time\": 1753478941.119949,\n  \"metric_analysis\": {\n    \"csmf_accuracy\": {\n      \"max\": 0.8650036791758646,\n      \"min\": 0.8650036791758646,\n      \"avg\": 0.8650036791758646,\n      \"last\": 0.8650036791758646,\n      \"last-5-avg\": 0.8650036791758646,\n      \"last-10-avg\": 0.8650036791758646\n    },\n    \"cod_accuracy\": {\n      \"max\": 0.26403818868287515,\n      \"min\": 0.26403818868287515,\n      \"avg\": 0.26403818868287515,\n      \"last\": 0.26403818868287515,\n      \"last-5-avg\": 0.26403818868287515,\n      \"last-10-avg\": 0.26403818868287515\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 0.14002108573913574,\n      \"min\": 0.14002108573913574,\n      \"avg\": 0.14002108573913574,\n      \"last\": 0.14002108573913574,\n      \"last-5-avg\": 0.14002108573913574,\n      \"last-10-avg\": 0.14002108573913574\n    },\n    \"time_total_s\": {\n      \"max\": 0.14002108573913574,\n      \"min\": 0.14002108573913574,\n      \"avg\": 0.14002108573913574,\n      \"last\": 0.14002108573913574,\n      \"last-5-avg\": 0.14002108573913574,\n      \"last-10-avg\": 0.14002108573913574\n    },\n    \"time_since_restore\": {\n      \"max\": 0.14002108573913574,\n      \"min\": 0.14002108573913574,\n      \"avg\": 0.14002108573913574,\n      \"last\": 0.14002108573913574,\n      \"last-5-avg\": 0.14002108573913574,\n      \"last-10-avg\": 0.14002108573913574\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"csmf_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308485c1f321caeeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308485c1f321caeeb3f9486945294612e\"\n      }\n    },\n    \"cod_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308056f526e00e6d03f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308056f526e00e6d03f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc1ec3600000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc1ec3600000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc1ec3600000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc1ec3600000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fc1ec3600000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fc1ec3600000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": 442844.758801375, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 200, "_metric": null, "_total_time": 1.4753379821777344, "_iteration": 80, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1753478934.036438, "_session_str": "2025-07-25_17-28-54", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f1000000000000008c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1753478934.036438}}