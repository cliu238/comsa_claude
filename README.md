# Context Engineering Template

A comprehensive template for getting started with Context Engineering - the discipline of engineering context for AI coding assistants so they have the information necessary to get the job done end to end.

> **Context Engineering is 10x better than prompt engineering and 100x better than vibe coding.**

## ðŸš€ Quick Start

```bash
# 1. Clone this template
git clone https://github.com/coleam00/Context-Engineering-Intro.git
cd Context-Engineering-Intro

# 2. Set up your project rules (optional - template provided)
# Edit CLAUDE.md to add your project-specific guidelines

# 3. Add examples (highly recommended)
# Place relevant code examples in the examples/ folder

# 4. Create your initial feature request
# Edit INITIAL.md with your feature requirements

# 5. Generate a comprehensive PRP (Product Requirements Prompt)
# In Claude Code, run:
/generate-prp INITIAL.md

# 6. Execute the PRP to implement your feature
# In Claude Code, run:
/execute-prp PRPs/your-feature-name.md
```

## ðŸ“š Table of Contents

- [What is Context Engineering?](#what-is-context-engineering)
- [Template Structure](#template-structure)
- [Step-by-Step Guide](#step-by-step-guide)
- [Writing Effective INITIAL.md Files](#writing-effective-initialmd-files)
- [The PRP Workflow](#the-prp-workflow)
- [Using Examples Effectively](#using-examples-effectively)
- [Best Practices](#best-practices)

## What is Context Engineering?

Context Engineering represents a paradigm shift from traditional prompt engineering:

### Prompt Engineering vs Context Engineering

**Prompt Engineering:**
- Focuses on clever wording and specific phrasing
- Limited to how you phrase a task
- Like giving someone a sticky note

**Context Engineering:**
- A complete system for providing comprehensive context
- Includes documentation, examples, rules, patterns, and validation
- Like writing a full screenplay with all the details

### Why Context Engineering Matters

1. **Reduces AI Failures**: Most agent failures aren't model failures - they're context failures
2. **Ensures Consistency**: AI follows your project patterns and conventions
3. **Enables Complex Features**: AI can handle multi-step implementations with proper context
4. **Self-Correcting**: Validation loops allow AI to fix its own mistakes

## Template Structure

```
context-engineering-intro/
â”œâ”€â”€ .claude/
â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”œâ”€â”€ generate-prp.md    # Generates comprehensive PRPs
â”‚   â”‚   â””â”€â”€ execute-prp.md     # Executes PRPs to implement features
â”‚   â””â”€â”€ settings.local.json    # Claude Code permissions
â”œâ”€â”€ PRPs/
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ prp_base.md       # Base template for PRPs
â”‚   â””â”€â”€ EXAMPLE_multi_agent_prp.md  # Example of a complete PRP
â”œâ”€â”€ examples/                  # Your code examples (critical!)
â”œâ”€â”€ CLAUDE.md                 # Global rules for AI assistant
â”œâ”€â”€ INITIAL.md               # Template for feature requests
â”œâ”€â”€ INITIAL_EXAMPLE.md       # Example feature request
â””â”€â”€ README.md                # This file
```

This template doesn't focus on RAG and tools with context engineering because I have a LOT more in store for that soon. ;)

## Step-by-Step Guide

### 1. Set Up Global Rules (CLAUDE.md)

The `CLAUDE.md` file contains project-wide rules that the AI assistant will follow in every conversation. The template includes:

- **Project awareness**: Reading planning docs, checking tasks
- **Code structure**: File size limits, module organization
- **Testing requirements**: Unit test patterns, coverage expectations
- **Style conventions**: Language preferences, formatting rules
- **Documentation standards**: Docstring formats, commenting practices

**You can use the provided template as-is or customize it for your project.**

### 2. Create Your Initial Feature Request

Edit `INITIAL.md` to describe what you want to build:

```markdown
## FEATURE:
[Describe what you want to build - be specific about functionality and requirements]

## EXAMPLES:
[List any example files in the examples/ folder and explain how they should be used]

## DOCUMENTATION:
[Include links to relevant documentation, APIs, or MCP server resources]

## OTHER CONSIDERATIONS:
[Mention any gotchas, specific requirements, or things AI assistants commonly miss]
```

**See `INITIAL_EXAMPLE.md` for a complete example.**

### 3. Generate the PRP

PRPs (Product Requirements Prompts) are comprehensive implementation blueprints that include:

- Complete context and documentation
- Implementation steps with validation
- Error handling patterns
- Test requirements

They are similar to PRDs (Product Requirements Documents) but are crafted more specifically to instruct an AI coding assistant.

Run in Claude Code:
```bash
/generate-prp INITIAL.md
```

**Note:** The slash commands are custom commands defined in `.claude/commands/`. You can view their implementation:
- `.claude/commands/generate-prp.md` - See how it researches and creates PRPs
- `.claude/commands/execute-prp.md` - See how it implements features from PRPs

The `$ARGUMENTS` variable in these commands receives whatever you pass after the command name (e.g., `INITIAL.md` or `PRPs/your-feature.md`).

This command will:
1. Read your feature request
2. Research the codebase for patterns
3. Search for relevant documentation
4. Create a comprehensive PRP in `PRPs/your-feature-name.md`

### 4. Execute the PRP

Once generated, execute the PRP to implement your feature:

```bash
/execute-prp PRPs/your-feature-name.md
```

The AI coding assistant will:
1. Read all context from the PRP
2. Create a detailed implementation plan
3. Execute each step with validation
4. Run tests and fix any issues
5. Ensure all success criteria are met

## Writing Effective INITIAL.md Files

### Key Sections Explained

**FEATURE**: Be specific and comprehensive
- âŒ "Build a web scraper"
- âœ… "Build an async web scraper using BeautifulSoup that extracts product data from e-commerce sites, handles rate limiting, and stores results in PostgreSQL"

**EXAMPLES**: Leverage the examples/ folder
- Place relevant code patterns in `examples/`
- Reference specific files and patterns to follow
- Explain what aspects should be mimicked

**DOCUMENTATION**: Include all relevant resources
- API documentation URLs
- Library guides
- MCP server documentation
- Database schemas

**OTHER CONSIDERATIONS**: Capture important details
- Authentication requirements
- Rate limits or quotas
- Common pitfalls
- Performance requirements

## The PRP Workflow

### How /generate-prp Works

The command follows this process:

1. **Research Phase**
   - Analyzes your codebase for patterns
   - Searches for similar implementations
   - Identifies conventions to follow

2. **Documentation Gathering**
   - Fetches relevant API docs
   - Includes library documentation
   - Adds gotchas and quirks

3. **Blueprint Creation**
   - Creates step-by-step implementation plan
   - Includes validation gates
   - Adds test requirements

4. **Quality Check**
   - Scores confidence level (1-10)
   - Ensures all context is included

### How /execute-prp Works

1. **Load Context**: Reads the entire PRP
2. **Plan**: Creates detailed task list using TodoWrite
3. **Execute**: Implements each component
4. **Validate**: Runs tests and linting
5. **Iterate**: Fixes any issues found
6. **Complete**: Ensures all requirements met

See `PRPs/EXAMPLE_multi_agent_prp.md` for a complete example of what gets generated.

## Using Examples Effectively

The `examples/` folder is **critical** for success. AI coding assistants perform much better when they can see patterns to follow.

### What to Include in Examples

1. **Code Structure Patterns**
   - How you organize modules
   - Import conventions
   - Class/function patterns

2. **Testing Patterns**
   - Test file structure
   - Mocking approaches
   - Assertion styles

3. **Integration Patterns**
   - API client implementations
   - Database connections
   - Authentication flows

4. **CLI Patterns**
   - Argument parsing
   - Output formatting
   - Error handling

### Example Structure

```
examples/
â”œâ”€â”€ README.md           # Explains what each example demonstrates
â”œâ”€â”€ cli.py             # CLI implementation pattern
â”œâ”€â”€ agent/             # Agent architecture patterns
â”‚   â”œâ”€â”€ agent.py      # Agent creation pattern
â”‚   â”œâ”€â”€ tools.py      # Tool implementation pattern
â”‚   â””â”€â”€ providers.py  # Multi-provider pattern
â””â”€â”€ tests/            # Testing patterns
    â”œâ”€â”€ test_agent.py # Unit test patterns
    â””â”€â”€ conftest.py   # Pytest configuration
```

## Best Practices

### 1. Be Explicit in INITIAL.md
- Don't assume the AI knows your preferences
- Include specific requirements and constraints
- Reference examples liberally

### 2. Provide Comprehensive Examples
- More examples = better implementations
- Show both what to do AND what not to do
- Include error handling patterns

### 3. Use Validation Gates
- PRPs include test commands that must pass
- AI will iterate until all validations succeed
- This ensures working code on first try

### 4. Leverage Documentation
- Include official API docs
- Add MCP server resources
- Reference specific documentation sections

### 5. Customize CLAUDE.md
- Add your conventions
- Include project-specific rules
- Define coding standards

## VA Data Processing Pipeline

### Overview

The `baseline` module provides a standardized pipeline for processing PHMRC (Population Health Metrics Research Consortium) Verbal Autopsy data. It supports two output formats:

1. **Numeric format** - For standard ML algorithms (scikit-learn, XGBoost, etc.)
2. **OpenVA format** - For InSilicoVA R package compatibility

### Installation

```bash
# 1. Initialize the va-data submodule
git submodule update --init --recursive

# 2. Install dependencies with Poetry
poetry install
```

### Usage

Run the example script to process PHMRC adult data:

```bash
poetry run python baseline/example_usage.py
```

This will:
- Load and validate PHMRC data using the PHMRCData class
- Apply OpenVA transformations
- Generate both numeric and OpenVA encoded outputs
- Save results to `results/baseline/processed_data/`

### Configuration

The pipeline uses a Pydantic-based configuration system:

```python
from baseline.config.data_config import DataConfig

config = DataConfig(
    data_path="data/raw/PHMRC/IHME_PHMRC_VA_DATA_ADULT_Y2013M09D11_0.csv",
    output_dir="results/baseline/",
    openva_encoding=False,  # True for InSilicoVA, False for ML
    drop_columns=[],        # Optional columns to exclude
    stratify_by_site=True   # Enable site-based stratification
)
```

### Output Files

The pipeline generates two files per processing run in `results/baseline/processed_data/`:

1. **CSV Data Files**
   - `adult_numeric_YYYYMMDD_HHMMSS.csv` - Numeric encoding for ML (0/1 values)
   - `adult_openva_YYYYMMDD_HHMMSS.csv` - OpenVA encoding for InSilicoVA ("Y"/""/".") 

2. **Metadata JSON Files**
   - Contains processing configuration, timestamp, data shape, column names, and cause-of-death distribution
   - Example: `adult_numeric_20250717_163737.metadata.json`

### Testing

Run unit tests with coverage:

```bash
poetry run pytest tests/baseline/ -v --cov=baseline
```

The core modules achieve >96% test coverage.

## Updated Project Structure

```
context-engineering-intro/
â”œâ”€â”€ .claude/
â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”œâ”€â”€ generate-prp.md    # Generates comprehensive PRPs
â”‚   â”‚   â””â”€â”€ execute-prp.md     # Executes PRPs to implement features
â”‚   â””â”€â”€ settings.local.json    # Claude Code permissions
â”œâ”€â”€ PRPs/
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ prp_base.md       # Base template for PRPs
â”‚   â”œâ”€â”€ EXAMPLE_multi_agent_prp.md  # Example of a complete PRP
â”‚   â””â”€â”€ va_data_processing_pipeline.md  # VA pipeline PRP
â”œâ”€â”€ baseline/                  # VA data processing module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_config.py    # Configuration management
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_loader_preprocessor.py  # Core processing logic
â”‚   â””â”€â”€ example_usage.py      # Usage demonstration
â”œâ”€â”€ examples/                  # Your code examples
â”‚   â””â”€â”€ data_validation.py    # Reference VA data processing
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ baseline/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_data_loader.py  # Unit tests
â”œâ”€â”€ results/
â”‚   â””â”€â”€ baseline/
â”‚       â”œâ”€â”€ processed_data/   # Output CSV and metadata files
â”‚       â””â”€â”€ logs/            # Processing logs
â”œâ”€â”€ va-data/                 # Git submodule for VA data utilities
â”œâ”€â”€ conftest.py             # Pytest configuration
â”œâ”€â”€ pyproject.toml          # Poetry dependencies
â”œâ”€â”€ CLAUDE.md               # Global rules for AI assistant
â”œâ”€â”€ INITIAL.md              # Template for feature requests
â””â”€â”€ README.md               # This file
```

## Resources

- [Claude Code Documentation](https://docs.anthropic.com/en/docs/claude-code)
- [Context Engineering Best Practices](https://www.philschmid.de/context-engineering)